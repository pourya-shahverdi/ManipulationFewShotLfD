{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T04:52:49.787517Z",
     "start_time": "2024-08-26T04:52:46.577047Z"
    },
    "executionInfo": {
     "elapsed": 6369,
     "status": "ok",
     "timestamp": 1716208275076,
     "user": {
      "displayName": "AliReza Beigy",
      "userId": "13191516012767928624"
     },
     "user_tz": -210
    },
    "id": "owVclBdNj54S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\arb\\miniconda3\\envs\\nao\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\arb\\miniconda3\\envs\\nao\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\arb\\miniconda3\\envs\\nao\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\arb\\miniconda3\\envs\\nao\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\arb\\miniconda3\\envs\\nao\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\arb\\miniconda3\\envs\\nao\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\arb\\miniconda3\\envs\\nao\\lib\\site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\arb\\miniconda3\\envs\\nao\\lib\\site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\arb\\miniconda3\\envs\\nao\\lib\\site-packages (from keras) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\arb\\miniconda3\\envs\\nao\\lib\\site-packages (from optree->keras) (4.10.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\arb\\miniconda3\\envs\\nao\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\arb\\miniconda3\\envs\\nao\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\arb\\miniconda3\\envs\\nao\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U keras"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:51:58.440635Z",
     "start_time": "2024-08-28T07:51:55.819890Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import glob\n",
    "import keras\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wandb.integration.keras3 import WandbMetricsLogger\n",
    "from torch.utils.data import Dataset, DataLoader, Subset"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:51:58.446154Z",
     "start_time": "2024-08-28T07:51:58.441651Z"
    }
   },
   "source": [
    "feature_columns = [\n",
    "    # 'LeftWristX', 'LeftWristY', 'LeftWristZ', \n",
    "    # 'LeftElbowX', 'LeftElbowY', 'LeftElbowZ', \n",
    "    # 'LeftShoulderX', 'LeftShoulderY', 'LeftShoulderZ', \n",
    "    'LeftElbowYaw', 'LeftElbowRoll', 'LeftShoulderRoll', 'LeftShoulderPitch',\n",
    "    'origin_x', 'origin_y', 'origin_z',\n",
    "    'direction'\n",
    "]\n",
    "output_columns = [\n",
    "    'LeftElbowYaw' #, 'LeftElbowRoll', 'LeftShoulderRoll', 'LeftShoulderPitch'\n",
    "]\n",
    "\n",
    "data_folder = glob.glob(r\"..\\NaoPushingData\\*\\processed_step_10.csv\")\n",
    "feature_shape = (10, len(feature_columns))  # (window, features)\n",
    "label_shape = (1, 1)  # (window, features)\n",
    "\n",
    "cache_base_dir = \"NaoCache\"\n",
    "\n",
    "column_ranges = {\n",
    "    'LeftElbowYaw': (-120, 120), 'LeftElbowRoll': (-90, 0),\n",
    "    'RightElbowYaw': (-120, 120), 'RightElbowRoll': (0, 90),\n",
    "    'LeftShoulderRoll': (-45, 90), 'LeftShoulderPitch': (-120, 120),\n",
    "    'RightShoulderRoll': (-90, 45), 'RightShoulderPitch': (-120, 120),\n",
    "    # 'LeftElbowYawCos': (-1, 1), 'LeftElbowRollCos': (-1, 1),\n",
    "    # 'RightElbowYawCos': (-1, 1), 'RightElbowRollCos': (-1, 1),\n",
    "    # 'LeftShoulderRollCos': (-1, 1), 'LeftShoulderPitchCos': (-1, 1),\n",
    "    # 'RightShoulderRollCos': (-1, 1), 'RightShoulderPitchCos': (-1, 1),\n",
    "    # 'LeftElbowYawSin': (-1, 1), 'LeftElbowRollSin': (-1, 1),\n",
    "    # 'RightElbowYawSin': (-1, 1), 'RightElbowRollSin': (-1, 1),\n",
    "    # 'LeftShoulderRollSin': (-1, 1), 'LeftShoulderPitchSin': (-1, 1),\n",
    "    # 'RightShoulderRollSin': (-1, 1), 'RightShoulderPitchSin': (-1, 1),\n",
    "    'LeftWristX': (-1, 1), 'LeftWristY': (-1, 1), 'LeftWristZ': (0, 3),\n",
    "    'RightWristX': (-1, 1), 'RightWristY': (-1, 1), 'RightWristZ': (0, 3),\n",
    "    'LeftElbowX': (-1, 1), 'LeftElbowY': (-1, 1), 'LeftElbowZ': (0, 3),\n",
    "    'RightElbowX': (-1, 1), 'RightElbowY': (-1, 1), 'RightElbowZ': (0, 3),\n",
    "    'LeftShoulderX': (-1, 1), 'LeftShoulderY': (-1, 1), 'LeftShoulderZ': (0, 3),\n",
    "    'RightShoulderX': (-1, 1), 'RightShoulderY': (-1, 1), 'RightShoulderZ': (0, 3),\n",
    "    'origin_x': (0, 640), 'origin_y': (0, 480), 'origin_z': (0, 7),\n",
    "    # 'LeftWristX_PX': (0, 640), 'LeftWristY_PX': (0, 480),\n",
    "    # 'RightWristX_PX': (0, 640), 'RightWristY_PX': (0, 480),\n",
    "    # 'LeftElbowX_PX': (0, 640), 'LeftElbowY_PX': (0, 480),\n",
    "    # 'RightElbowX_PX': (0, 640), 'RightElbowY_PX': (0, 480),\n",
    "    # 'LeftShoulderX_PX': (0, 640), 'LeftShoulderY_PX': (0, 480),\n",
    "    # 'RightShoulderX_PX': (0, 640), 'RightShoulderY_PX': (0, 480),\n",
    "    # 'WristBallDistance': (0, 800), 'WristBoxDistance': (0, 800), 'BallBoxDistance': (0, 800)\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:51:58.452959Z",
     "start_time": "2024-08-28T07:51:58.446655Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def normalize_columns(df):\n",
    "    for column, (min_val, max_val) in column_ranges.items():\n",
    "        df[column] = (df[column] - min_val) / (max_val - min_val)\n",
    "        if min_val < 0:\n",
    "            df[column] = 2 * df[column] - 1\n",
    "    return df\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_folder, feature_columns, output_columns, label_shape):\n",
    "        self.data_folder = data_folder\n",
    "        self.feature_columns = feature_columns\n",
    "        self.output_columns = output_columns\n",
    "        self.label_shape = label_shape\n",
    "        self.data = list(self.generator())\n",
    "\n",
    "    def generator(self):\n",
    "        for file in self.data_folder:\n",
    "            df = pd.read_csv(file)\n",
    "            df = df.dropna()\n",
    "            df = normalize_columns(df)\n",
    "\n",
    "            selected_features = df[self.feature_columns].values.astype(np.float64)\n",
    "            raw_data = df[self.output_columns].values.astype(np.float64)\n",
    "            \n",
    "            min_skip = 5\n",
    "            for i in range(0, len(df) - 1):\n",
    "                if i < feature_shape[0]:\n",
    "                    features = selected_features[:i + 1]\n",
    "\n",
    "                    num_rows, num_columns = features.shape\n",
    "                    num_rows_to_add = feature_shape[0] - num_rows\n",
    "                    new_rows_array = np.full((num_rows_to_add, num_columns), 0)\n",
    "                    features = np.concatenate((new_rows_array, features), axis=0)\n",
    "                else:\n",
    "                    features = selected_features[i - feature_shape[0] + 1:i + 1]\n",
    "\n",
    "                current_label = raw_data[i:i + self.label_shape[0]]\n",
    "                for skip in range(min_skip, 100):\n",
    "                    diff = 0 if i + skip < len(df) - 1 else -len(df) + i + skip + 2\n",
    "                    next_label = raw_data[i + 1 + skip - diff:i + 1 + skip - diff + self.label_shape[0]]\n",
    "                    # labels = next_label - current_label\n",
    "                    labels = next_label\n",
    "                    labels = labels.squeeze(0)\n",
    "                    min_skip = skip\n",
    "                    if abs((next_label - current_label)[0]).sum() > 0.2:\n",
    "                        break\n",
    "                        \n",
    "                labels = torch.tensor(labels, dtype=torch.float64, device=device)\n",
    "                \n",
    "                yield torch.tensor(features, dtype=torch.float64, device=device), dict(zip(map(lambda x: f'output_{x}', self.output_columns), labels))\n",
    "                yield torch.tensor(np.repeat(selected_features[i:i + 1], feature_shape[0], axis=0), dtype=torch.float64, device=device), dict(zip(map(lambda x: f'output_{x}', self.output_columns), labels))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset(data_folder, output_columns, label_shape, cache_path=None):\n",
    "    if cache_path and os.path.exists(cache_path):\n",
    "        dataset = torch.load(cache_path)\n",
    "    else:\n",
    "        dataset = CustomDataset(data_folder, feature_columns, output_columns, label_shape)\n",
    "        # if cache_path:\n",
    "        #     torch.save(dataset, cache_path)\n",
    "\n",
    "    return dataset"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:51:58.458643Z",
     "start_time": "2024-08-28T07:51:58.452959Z"
    }
   },
   "source": [
    "def split_dataset(dataset, train_size, batch_size):\n",
    "    dataset_size = len(dataset)\n",
    "    train_size = int(dataset_size * train_size)\n",
    "\n",
    "    indices = list(range(dataset_size))\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:]\n",
    "\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:51:58.468276Z",
     "start_time": "2024-08-28T07:51:58.458643Z"
    }
   },
   "source": [
    "def train_and_merge_models(data_folder, output_columns, feature_shape, label_shape, cache_base_dir, split_ratio=0.8, batch_size=4096):\n",
    "    # wandb.init(project=\"GbN\", entity=\"GbN\")\n",
    "    \n",
    "    dataset = create_dataset(data_folder, output_columns, label_shape, cache_path=cache_base_dir)\n",
    "    dataset_train, dataset_val = split_dataset(dataset, split_ratio, batch_size)\n",
    "\n",
    "\n",
    "    # Create input layer (shared)\n",
    "    initializer = keras.initializers.GlorotUniform(seed=42)\n",
    "    input_layer = keras.layers.Input(shape=feature_shape)\n",
    "    \n",
    "    # Shared Backbone layers with Residual Connections\n",
    "    x = keras.layers.Dense(256, activation='relu', kernel_initializer=initializer,\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))(input_layer)\n",
    "    \n",
    "    # Residual connection 1\n",
    "    # residual = x\n",
    "    \n",
    "    x = keras.layers.Dense(256, activation='relu', kernel_initializer=initializer,\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))(x)\n",
    "    \n",
    "    # # Add first residual connection\n",
    "    # x = keras.layers.Add()([x, residual])  # Adding the residual connection\n",
    "    # \n",
    "    # # Residual connection 2\n",
    "    # residual = x\n",
    "    \n",
    "    x = keras.layers.Dense(256, activation='relu', kernel_initializer=initializer,\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))(x)\n",
    "    \n",
    "    # Add second residual connection\n",
    "    # x = keras.layers.Add()([x, residual])  # Adding the residual connection\n",
    "    \n",
    "    x = keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=False, kernel_initializer=initializer))(x)\n",
    "    \n",
    "    # Branch for each output\n",
    "    outputs = []\n",
    "    for i, output_column in enumerate(output_columns):\n",
    "        # Branch with Residual Connections\n",
    "        branch = keras.layers.Dense(256, activation='relu', kernel_initializer=initializer,\n",
    "                                    kernel_regularizer=keras.regularizers.l2(0.01))(x)\n",
    "    \n",
    "        # Residual connection in branch\n",
    "        # branch_residual = branch\n",
    "    \n",
    "        branch = keras.layers.Dense(256, activation='relu', kernel_initializer=initializer,\n",
    "                                    kernel_regularizer=keras.regularizers.l2(0.01))(branch)\n",
    "    \n",
    "        # Add residual connection in branch\n",
    "        # branch = keras.layers.Add()([branch, branch_residual])  # Adding the residual connection\n",
    "    \n",
    "        # branch_residual = branch  # Update the residual\n",
    "    \n",
    "        branch = keras.layers.Dense(256, activation='relu', kernel_initializer=initializer,\n",
    "                                    kernel_regularizer=keras.regularizers.l2(0.01))(branch)\n",
    "    \n",
    "        # Add another residual connection in branch\n",
    "        # branch = keras.layers.Add()([branch, branch_residual])  # Adding the residual connection\n",
    "    \n",
    "        output_layer = keras.layers.Dense(label_shape[0], activation='linear', kernel_initializer=initializer,\n",
    "                                          name=f'output_{output_column}')(branch)\n",
    "        outputs.append({f'output_{output_column}': output_layer})\n",
    "    \n",
    "    # Create the model with multiple outputs\n",
    "    model = keras.models.Model(inputs=input_layer, outputs=outputs)\n",
    "\n",
    "    # Define loss and metrics for each output\n",
    "    loss_dict = {f'output_{output_column}': 'mse' for output_column in output_columns}\n",
    "    metrics_dict = {f'output_{output_column}': ['mae'] for output_column in output_columns}\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.AdamW(learning_rate=0.1),\n",
    "                  loss=loss_dict, metrics=metrics_dict\n",
    "                  )\n",
    "\n",
    "    # Print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # Callbacks\n",
    "    lr_reducer = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=0.0000001)\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, verbose=1, restore_best_weights=True)\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(f\"best_model_merged.keras\", monitor='val_loss', verbose=1,\n",
    "                                                       save_best_only=True, mode='min')\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(dataset_train, validation_data=dataset_val, epochs=1000,\n",
    "                        callbacks=[\n",
    "                            lr_reducer, early_stop, model_checkpoint#, WandbMetricsLogger()\n",
    "                        ])\n",
    "\n",
    "    # Extract and log-transform the loss data\n",
    "    epoch = np.arange(1, len(history.history[f'loss']) + 1)\n",
    "    training_loss = np.log(history.history[f'loss'])\n",
    "    validation_loss = np.log(history.history[f'val_loss'])\n",
    "\n",
    "    # Create a plot for each output\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epoch, training_loss, linestyle='-', color='b', label=f'Training Log Loss')\n",
    "    plt.plot(epoch, validation_loss, linestyle='-', color='r', label=f'Validation Log Loss')\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.xlabel('Epochs', fontsize=20)\n",
    "    plt.ylabel('Log Loss', fontsize=20)\n",
    "\n",
    "    # Customize x-axis and y-axis tick label font size\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    # Add grid and legend\n",
    "    plt.grid(True)\n",
    "    plt.legend(fontsize=12)\n",
    "\n",
    "    # Save the plot as a high-quality PDF file\n",
    "    plt.savefig(f'validation_loss.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "\n",
    "    # Show the plot (optional)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training and validation losses for each output\n",
    "    for i, output_column in enumerate(output_columns):\n",
    "        # Extract and log-transform the loss data\n",
    "        epoch = np.arange(1, len(history.history[f'output_{output_column}_loss']) + 1)\n",
    "        training_loss = np.log(history.history[f'output_{output_column}_loss'])\n",
    "        validation_loss = np.log(history.history[f'val_output_{output_column}_loss'])\n",
    "\n",
    "        # Create a plot for each output\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(epoch, training_loss, linestyle='-', color='b', label=f'Training Log Loss {output_column}')\n",
    "        plt.plot(epoch, validation_loss, linestyle='-', color='r', label=f'Validation Log Loss {output_column}')\n",
    "\n",
    "        # Add titles and labels\n",
    "        plt.xlabel('Epochs', fontsize=20)\n",
    "        plt.ylabel('Log Loss', fontsize=20)\n",
    "\n",
    "        # Customize x-axis and y-axis tick label font size\n",
    "        plt.xticks(fontsize=18)\n",
    "        plt.yticks(fontsize=18)\n",
    "\n",
    "        # Add grid and legend\n",
    "        plt.grid(True)\n",
    "        plt.legend(fontsize=12)\n",
    "\n",
    "        # Save the plot as a high-quality PDF file\n",
    "        plt.savefig(f'validation_loss_{output_column}.pdf', format='pdf', bbox_inches='tight', dpi=300)\n",
    "\n",
    "        # Show the plot (optional)\n",
    "        plt.show()\n",
    "    # plt.plot(np.log(history.history[f'loss']), label=f'Training Log Loss')\n",
    "    # plt.plot(np.log(history.history[f'val_loss']), label=f'Validation Log Loss')\n",
    "    # plt.title(f'Training and Validation Loss')\n",
    "    # plt.xlabel('Epochs')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "    # # Plot training and validation losses for each output\n",
    "    # for i, output_column in enumerate(output_columns):\n",
    "    #     plt.plot(np.log(history.history[f'output_{output_column}_loss']), label=f'Training Log Loss {output_column}')\n",
    "    #     plt.plot(np.log(history.history[f'val_output_{output_column}_loss']), label=f'Validation Log Loss {output_column}')\n",
    "    #     plt.title(f'Training and Validation Loss for {output_column}')\n",
    "    #     plt.xlabel('Epochs')\n",
    "    #     plt.ylabel('Loss')\n",
    "    #     plt.legend()\n",
    "    #     plt.show()\n",
    "    \n",
    "    return history"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:54:28.246759Z",
     "start_time": "2024-08-28T07:51:58.468276Z"
    }
   },
   "source": "history = train_and_merge_models(data_folder, output_columns, feature_shape, label_shape, cache_base_dir)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001B[38;5;33mInputLayer\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m8\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m256\u001B[0m)        │         \u001B[38;5;34m2,304\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m256\u001B[0m)        │        \u001B[38;5;34m65,792\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m256\u001B[0m)        │        \u001B[38;5;34m65,792\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001B[38;5;33mBidirectional\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1024\u001B[0m)           │     \u001B[38;5;34m3,149,824\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │       \u001B[38;5;34m262,400\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │        \u001B[38;5;34m65,792\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │        \u001B[38;5;34m65,792\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_LeftElbowYaw (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m257\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,149,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_LeftElbowYaw (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m3,677,953\u001B[0m (14.03 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,677,953</span> (14.03 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m3,677,953\u001B[0m (14.03 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,677,953</span> (14.03 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 246ms/step - loss: 14.8407 - mae: 0.5014\n",
      "Epoch 1: val_loss improved from inf to 293768.84375, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 208ms/step - loss: 104136.2734 - mae: 70.3622 - val_loss: 293768.8438 - val_mae: 541.9755 - learning_rate: 0.1000\n",
      "Epoch 2/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 293124.2812 - mae: 541.3779\n",
      "Epoch 2: val_loss did not improve from 293768.84375\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step - loss: 280201.1250 - mae: 522.2018 - val_loss: 13187173.0000 - val_mae: 3631.4043 - learning_rate: 0.1000\n",
      "Epoch 3/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 13191293.0000 - mae: 3631.9702\n",
      "Epoch 3: val_loss improved from 293768.84375 to 3418.50684, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 188ms/step - loss: 12572580.0000 - mae: 3462.7954 - val_loss: 3418.5068 - val_mae: 57.4105 - learning_rate: 0.1000\n",
      "Epoch 4/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 3391.0696 - mae: 57.1757\n",
      "Epoch 4: val_loss did not improve from 3418.50684\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - loss: 3245.7883 - mae: 55.0480 - val_loss: 15507.6807 - val_mae: 123.7687 - learning_rate: 0.1000\n",
      "Epoch 5/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 15447.8184 - mae: 123.5288\n",
      "Epoch 5: val_loss improved from 3418.50684 to 668.42664, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 14816.0830 - mae: 119.7011 - val_loss: 668.4266 - val_mae: 20.3363 - learning_rate: 0.1000\n",
      "Epoch 6/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 657.7197 - mae: 20.0856\n",
      "Epoch 6: val_loss did not improve from 668.42664\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - loss: 658.7988 - mae: 20.0764 - val_loss: 5834.0391 - val_mae: 74.2828 - learning_rate: 0.1000\n",
      "Epoch 7/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 5797.9238 - mae: 74.0429\n",
      "Epoch 7: val_loss did not improve from 668.42664\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 10257.4521 - mae: 85.4418 - val_loss: 8435.4365 - val_mae: 89.7950 - learning_rate: 0.1000\n",
      "Epoch 8/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 8391.8779 - mae: 89.5550\n",
      "Epoch 8: val_loss did not improve from 668.42664\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step - loss: 9061.1689 - mae: 92.3532 - val_loss: 9393.9395 - val_mae: 94.7248 - learning_rate: 0.1000\n",
      "Epoch 9/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 269ms/step - loss: 9348.0146 - mae: 94.4849\n",
      "Epoch 9: val_loss did not improve from 668.42664\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 8945.5605 - mae: 90.8987 - val_loss: 8870.2021 - val_mae: 91.6818 - learning_rate: 0.1000\n",
      "Epoch 10/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 8925.9990 - mae: 91.9889\n",
      "Epoch 10: val_loss did not improve from 668.42664\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step - loss: 8624.8545 - mae: 89.7834 - val_loss: 26225.2031 - val_mae: 160.3843 - learning_rate: 0.1000\n",
      "Epoch 11/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 26147.7695 - mae: 160.1443\n",
      "Epoch 11: val_loss did not improve from 668.42664\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step - loss: 24952.5664 - mae: 153.2048 - val_loss: 1370.4885 - val_mae: 28.9215 - learning_rate: 0.1000\n",
      "Epoch 12/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 1383.8966 - mae: 29.1614\n",
      "Epoch 12: val_loss did not improve from 668.42664\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - loss: 1380.9067 - mae: 29.0973 - val_loss: 803.3510 - val_mae: 15.5571 - learning_rate: 0.1000\n",
      "Epoch 13/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 810.3459 - mae: 15.7971\n",
      "Epoch 13: val_loss did not improve from 668.42664\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step - loss: 799.6881 - mae: 15.2081 - val_loss: 945.8381 - val_mae: 19.0185 - learning_rate: 0.1000\n",
      "Epoch 14/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 936.2731 - mae: 18.7794\n",
      "Epoch 14: val_loss did not improve from 668.42664\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 55ms/step - loss: 953.0887 - mae: 19.1408 - val_loss: 1029.0481 - val_mae: 20.6400 - learning_rate: 0.1000\n",
      "Epoch 15/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 1018.6736 - mae: 20.4001\n",
      "Epoch 15: val_loss did not improve from 668.42664\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 1000.4117 - mae: 19.6464 - val_loss: 948.8081 - val_mae: 18.1712 - learning_rate: 0.1000\n",
      "Epoch 16/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 957.0575 - mae: 18.4111\n",
      "Epoch 16: val_loss did not improve from 668.42664\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 955.9289 - mae: 18.3792 - val_loss: 890.2958 - val_mae: 16.4456 - learning_rate: 0.0100\n",
      "Epoch 17/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 897.7172 - mae: 16.6855\n",
      "Epoch 17: val_loss did not improve from 668.42664\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - loss: 892.9673 - mae: 16.5265 - val_loss: 721.5866 - val_mae: 10.0421 - learning_rate: 0.0100\n",
      "Epoch 18/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 725.9352 - mae: 10.2820\n",
      "Epoch 18: val_loss improved from 668.42664 to 626.53003, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 188ms/step - loss: 722.4681 - mae: 10.0632 - val_loss: 626.5300 - val_mae: 2.2621 - learning_rate: 0.0100\n",
      "Epoch 19/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 627.1453 - mae: 2.5021\n",
      "Epoch 19: val_loss improved from 626.53003 to 623.58624, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 626.8594 - mae: 2.4015 - val_loss: 623.5862 - val_mae: 1.2927 - learning_rate: 0.0100\n",
      "Epoch 20/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 622.4961 - mae: 1.0521\n",
      "Epoch 20: val_loss did not improve from 623.58624\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step - loss: 622.9075 - mae: 1.1495 - val_loss: 638.2699 - val_mae: 3.9965 - learning_rate: 0.0100\n",
      "Epoch 21/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 635.8819 - mae: 3.7566\n",
      "Epoch 21: val_loss did not improve from 623.58624\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 636.5206 - mae: 3.8272 - val_loss: 652.8870 - val_mae: 5.5058 - learning_rate: 0.0100\n",
      "Epoch 22/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 649.7748 - mae: 5.2659\n",
      "Epoch 22: val_loss did not improve from 623.58624\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - loss: 650.2338 - mae: 5.3062 - val_loss: 655.6482 - val_mae: 5.7358 - learning_rate: 0.0100\n",
      "Epoch 23/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 652.4255 - mae: 5.4959\n",
      "Epoch 23: val_loss did not improve from 623.58624\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step - loss: 652.5642 - mae: 5.5084 - val_loss: 646.3351 - val_mae: 4.8483 - learning_rate: 0.0100\n",
      "Epoch 24/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 643.5384 - mae: 4.6083\n",
      "Epoch 24: val_loss did not improve from 623.58624\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 55ms/step - loss: 643.4615 - mae: 4.6004 - val_loss: 632.9869 - val_mae: 3.1876 - learning_rate: 0.0100\n",
      "Epoch 25/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 630.9872 - mae: 2.9476\n",
      "Epoch 25: val_loss did not improve from 623.58624\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - loss: 630.8791 - mae: 2.9292 - val_loss: 624.1770 - val_mae: 1.2038 - learning_rate: 0.0100\n",
      "Epoch 26/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 623.1346 - mae: 0.9568\n",
      "Epoch 26: val_loss improved from 623.58624 to 623.12109, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 623.0991 - mae: 0.9381 - val_loss: 623.1211 - val_mae: 0.9358 - learning_rate: 0.0100\n",
      "Epoch 27/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 622.9860 - mae: 0.9643\n",
      "Epoch 27: val_loss did not improve from 623.12109\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 622.9968 - mae: 0.9725 - val_loss: 627.0034 - val_mae: 2.1284 - learning_rate: 0.0100\n",
      "Epoch 28/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 627.5546 - mae: 2.3683\n",
      "Epoch 28: val_loss did not improve from 623.12109\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 627.5189 - mae: 2.3626 - val_loss: 630.6031 - val_mae: 2.8844 - learning_rate: 0.0100\n",
      "Epoch 29/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 631.5170 - mae: 3.1243\n",
      "Epoch 29: val_loss did not improve from 623.12109\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step - loss: 631.3757 - mae: 3.1015 - val_loss: 630.6019 - val_mae: 2.9213 - learning_rate: 0.0100\n",
      "Epoch 30/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 631.5336 - mae: 3.1612\n",
      "Epoch 30: val_loss did not improve from 623.12109\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 631.3130 - mae: 3.1231 - val_loss: 627.3489 - val_mae: 2.3493 - learning_rate: 0.0100\n",
      "Epoch 31/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 628.0060 - mae: 2.5892\n",
      "Epoch 31: val_loss did not improve from 623.12109\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - loss: 627.7933 - mae: 2.5405 - val_loss: 623.5020 - val_mae: 1.4435 - learning_rate: 0.0100\n",
      "Epoch 32/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 623.6986 - mae: 1.6338\n",
      "Epoch 32: val_loss improved from 623.12109 to 621.39294, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 623.5742 - mae: 1.5807 - val_loss: 621.3929 - val_mae: 0.7460 - learning_rate: 0.0100\n",
      "Epoch 33/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 621.0724 - mae: 0.6104\n",
      "Epoch 33: val_loss did not improve from 621.39294\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 621.0601 - mae: 0.6071 - val_loss: 621.4044 - val_mae: 0.8809 - learning_rate: 0.0100\n",
      "Epoch 34/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 620.6318 - mae: 0.5274\n",
      "Epoch 34: val_loss did not improve from 621.39294\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 620.6969 - mae: 0.5655 - val_loss: 622.2737 - val_mae: 1.2545 - learning_rate: 0.0100\n",
      "Epoch 35/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 621.2032 - mae: 1.0121\n",
      "Epoch 35: val_loss did not improve from 621.39294\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - loss: 621.2887 - mae: 1.0473 - val_loss: 622.5494 - val_mae: 1.4653 - learning_rate: 0.0100\n",
      "Epoch 36/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 621.3761 - mae: 1.2254\n",
      "Epoch 36: val_loss did not improve from 621.39294\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - loss: 621.4410 - mae: 1.2511 - val_loss: 621.7603 - val_mae: 1.2935 - learning_rate: 0.0100\n",
      "Epoch 37/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 620.6697 - mae: 1.0529\n",
      "Epoch 37: val_loss improved from 621.39294 to 620.47247, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 191ms/step - loss: 620.7029 - mae: 1.0712 - val_loss: 620.4725 - val_mae: 0.9794 - learning_rate: 0.0100\n",
      "Epoch 38/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 619.6002 - mae: 0.6671\n",
      "Epoch 38: val_loss improved from 620.47247 to 619.51196, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 619.6092 - mae: 0.6782 - val_loss: 619.5120 - val_mae: 0.7652 - learning_rate: 0.0100\n",
      "Epoch 39/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 618.9197 - mae: 0.3738\n",
      "Epoch 39: val_loss improved from 619.51196 to 619.20923, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 618.9117 - mae: 0.3734 - val_loss: 619.2092 - val_mae: 0.7412 - learning_rate: 0.0100\n",
      "Epoch 40/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 618.8821 - mae: 0.5988\n",
      "Epoch 40: val_loss did not improve from 619.20923\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step - loss: 618.8571 - mae: 0.5879 - val_loss: 619.2706 - val_mae: 0.9325 - learning_rate: 0.0100\n",
      "Epoch 41/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 619.1328 - mae: 0.9591\n",
      "Epoch 41: val_loss improved from 619.20923 to 619.19952, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 619.0888 - mae: 0.9361 - val_loss: 619.1995 - val_mae: 1.0504 - learning_rate: 0.0100\n",
      "Epoch 42/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 619.1425 - mae: 1.1188\n",
      "Epoch 42: val_loss improved from 619.19952 to 618.76404, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 619.0847 - mae: 1.0901 - val_loss: 618.7640 - val_mae: 1.0054 - learning_rate: 0.0100\n",
      "Epoch 43/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 618.6776 - mae: 1.0603\n",
      "Epoch 43: val_loss improved from 618.76404 to 618.10730, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 618.6196 - mae: 1.0292 - val_loss: 618.1073 - val_mae: 0.8609 - learning_rate: 0.0100\n",
      "Epoch 44/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 617.9076 - mae: 0.8382\n",
      "Epoch 44: val_loss improved from 618.10730 to 617.51208, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 617.8645 - mae: 0.8157 - val_loss: 617.5121 - val_mae: 0.7232 - learning_rate: 0.0100\n",
      "Epoch 45/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 617.1582 - mae: 0.5531\n",
      "Epoch 45: val_loss improved from 617.51208 to 617.12146, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 617.1379 - mae: 0.5437 - val_loss: 617.1215 - val_mae: 0.7374 - learning_rate: 0.0100\n",
      "Epoch 46/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 616.6184 - mae: 0.3804\n",
      "Epoch 46: val_loss improved from 617.12146 to 616.86395, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 616.6181 - mae: 0.3882 - val_loss: 616.8640 - val_mae: 0.7728 - learning_rate: 0.0100\n",
      "Epoch 47/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 616.2544 - mae: 0.3809\n",
      "Epoch 47: val_loss improved from 616.86395 to 616.58783, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 616.2647 - mae: 0.3961 - val_loss: 616.5878 - val_mae: 0.7941 - learning_rate: 0.0100\n",
      "Epoch 48/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 615.9346 - mae: 0.4066\n",
      "Epoch 48: val_loss improved from 616.58783 to 616.22070, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 615.9456 - mae: 0.4217 - val_loss: 616.2207 - val_mae: 0.7842 - learning_rate: 0.0100\n",
      "Epoch 49/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 270ms/step - loss: 615.5872 - mae: 0.3934\n",
      "Epoch 49: val_loss improved from 616.22070 to 615.80786, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 615.5925 - mae: 0.4046 - val_loss: 615.8079 - val_mae: 0.7556 - learning_rate: 0.0100\n",
      "Epoch 50/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 615.2413 - mae: 0.3679\n",
      "Epoch 50: val_loss improved from 615.80786 to 615.43079, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 615.2383 - mae: 0.3726 - val_loss: 615.4308 - val_mae: 0.7313 - learning_rate: 0.0100\n",
      "Epoch 51/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 614.9523 - mae: 0.3960\n",
      "Epoch 51: val_loss improved from 615.43079 to 615.11713, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 614.9407 - mae: 0.3940 - val_loss: 615.1171 - val_mae: 0.7140 - learning_rate: 0.0100\n",
      "Epoch 52/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 614.7203 - mae: 0.4881\n",
      "Epoch 52: val_loss improved from 615.11713 to 614.82800, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 614.7010 - mae: 0.4815 - val_loss: 614.8280 - val_mae: 0.7304 - learning_rate: 0.0100\n",
      "Epoch 53/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 614.4853 - mae: 0.5718\n",
      "Epoch 53: val_loss improved from 614.82800 to 614.51154, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 614.4605 - mae: 0.5615 - val_loss: 614.5115 - val_mae: 0.7418 - learning_rate: 0.0100\n",
      "Epoch 54/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 614.1854 - mae: 0.6004\n",
      "Epoch 54: val_loss improved from 614.51154 to 614.15387, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 614.1589 - mae: 0.5887 - val_loss: 614.1539 - val_mae: 0.7287 - learning_rate: 0.0100\n",
      "Epoch 55/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 613.8085 - mae: 0.5674\n",
      "Epoch 55: val_loss improved from 614.15387 to 613.78027, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 613.7847 - mae: 0.5571 - val_loss: 613.7803 - val_mae: 0.7134 - learning_rate: 0.0100\n",
      "Epoch 56/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 613.3918 - mae: 0.5002\n",
      "Epoch 56: val_loss improved from 613.78027 to 613.42126, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 613.3737 - mae: 0.4931 - val_loss: 613.4213 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 57/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 612.9821 - mae: 0.4330\n",
      "Epoch 57: val_loss improved from 613.42126 to 613.08417, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 612.9702 - mae: 0.4302 - val_loss: 613.0842 - val_mae: 0.7320 - learning_rate: 0.0100\n",
      "Epoch 58/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 612.6025 - mae: 0.3935\n",
      "Epoch 58: val_loss improved from 613.08417 to 612.75598, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 194ms/step - loss: 612.5953 - mae: 0.3947 - val_loss: 612.7560 - val_mae: 0.7380 - learning_rate: 0.0100\n",
      "Epoch 59/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 612.2510 - mae: 0.3794\n",
      "Epoch 59: val_loss improved from 612.75598 to 612.42413, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 612.2457 - mae: 0.3822 - val_loss: 612.4241 - val_mae: 0.7382 - learning_rate: 0.0100\n",
      "Epoch 60/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 611.9183 - mae: 0.3790\n",
      "Epoch 60: val_loss improved from 612.42413 to 612.08862, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 611.9122 - mae: 0.3811 - val_loss: 612.0886 - val_mae: 0.7336 - learning_rate: 0.0100\n",
      "Epoch 61/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 611.6006 - mae: 0.3889\n",
      "Epoch 61: val_loss improved from 612.08862 to 611.75708, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 611.5921 - mae: 0.3889 - val_loss: 611.7571 - val_mae: 0.7268 - learning_rate: 0.0100\n",
      "Epoch 62/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 611.2972 - mae: 0.4122\n",
      "Epoch 62: val_loss improved from 611.75708 to 611.43317, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 611.2855 - mae: 0.4097 - val_loss: 611.4332 - val_mae: 0.7206 - learning_rate: 0.0100\n",
      "Epoch 63/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 611.0014 - mae: 0.4415\n",
      "Epoch 63: val_loss improved from 611.43317 to 611.11237, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 610.9868 - mae: 0.4372 - val_loss: 611.1124 - val_mae: 0.7166 - learning_rate: 0.0100\n",
      "Epoch 64/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 610.7003 - mae: 0.4667\n",
      "Epoch 64: val_loss improved from 611.11237 to 610.78772, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 610.6837 - mae: 0.4611 - val_loss: 610.7877 - val_mae: 0.7153 - learning_rate: 0.0100\n",
      "Epoch 65/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 610.3824 - mae: 0.4761\n",
      "Epoch 65: val_loss improved from 610.78772 to 610.45715, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 610.3654 - mae: 0.4700 - val_loss: 610.4572 - val_mae: 0.7164 - learning_rate: 0.0100\n",
      "Epoch 66/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 610.0459 - mae: 0.4680\n",
      "Epoch 66: val_loss improved from 610.45715 to 610.12390, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 610.0298 - mae: 0.4624 - val_loss: 610.1239 - val_mae: 0.7193 - learning_rate: 0.0100\n",
      "Epoch 67/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 609.6984 - mae: 0.4490\n",
      "Epoch 67: val_loss improved from 610.12390 to 609.79272, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 609.6841 - mae: 0.4446 - val_loss: 609.7927 - val_mae: 0.7229 - learning_rate: 0.0100\n",
      "Epoch 68/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 609.3500 - mae: 0.4292\n",
      "Epoch 68: val_loss improved from 609.79272 to 609.46527, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 609.3378 - mae: 0.4261 - val_loss: 609.4653 - val_mae: 0.7260 - learning_rate: 0.0100\n",
      "Epoch 69/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 609.0088 - mae: 0.4154\n",
      "Epoch 69: val_loss improved from 609.46527 to 609.14044, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 608.9980 - mae: 0.4133 - val_loss: 609.1404 - val_mae: 0.7276 - learning_rate: 0.0100\n",
      "Epoch 70/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 608.6771 - mae: 0.4090\n",
      "Epoch 70: val_loss improved from 609.14044 to 608.81720, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 608.6669 - mae: 0.4074 - val_loss: 608.8172 - val_mae: 0.7273 - learning_rate: 0.0100\n",
      "Epoch 71/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 608.3549 - mae: 0.4100\n",
      "Epoch 71: val_loss improved from 608.81720 to 608.49536, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 179ms/step - loss: 608.3444 - mae: 0.4081 - val_loss: 608.4954 - val_mae: 0.7257 - learning_rate: 0.0100\n",
      "Epoch 72/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 608.0403 - mae: 0.4168\n",
      "Epoch 72: val_loss improved from 608.49536 to 608.17542, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 177ms/step - loss: 608.0289 - mae: 0.4142 - val_loss: 608.1754 - val_mae: 0.7234 - learning_rate: 0.0100\n",
      "Epoch 73/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 607.7303 - mae: 0.4267\n",
      "Epoch 73: val_loss improved from 608.17542 to 607.85693, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 607.7178 - mae: 0.4234 - val_loss: 607.8569 - val_mae: 0.7215 - learning_rate: 0.0100\n",
      "Epoch 74/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 607.4209 - mae: 0.4365\n",
      "Epoch 74: val_loss improved from 607.85693 to 607.53864, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 607.4074 - mae: 0.4326 - val_loss: 607.5386 - val_mae: 0.7204 - learning_rate: 0.0100\n",
      "Epoch 75/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 607.1079 - mae: 0.4427\n",
      "Epoch 75: val_loss improved from 607.53864 to 607.21973, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 607.0939 - mae: 0.4385 - val_loss: 607.2197 - val_mae: 0.7203 - learning_rate: 0.0100\n",
      "Epoch 76/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 606.7895 - mae: 0.4434\n",
      "Epoch 76: val_loss improved from 607.21973 to 606.90015, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 606.7756 - mae: 0.4391 - val_loss: 606.9001 - val_mae: 0.7210 - learning_rate: 0.0100\n",
      "Epoch 77/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 606.4664 - mae: 0.4391\n",
      "Epoch 77: val_loss improved from 606.90015 to 606.58099, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 606.4531 - mae: 0.4352 - val_loss: 606.5810 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 78/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 606.1415 - mae: 0.4326\n",
      "Epoch 78: val_loss improved from 606.58099 to 606.26306, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 178ms/step - loss: 606.1289 - mae: 0.4291 - val_loss: 606.2631 - val_mae: 0.7234 - learning_rate: 0.0100\n",
      "Epoch 79/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 605.8180 - mae: 0.4267\n",
      "Epoch 79: val_loss improved from 606.26306 to 605.94653, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 605.8060 - mae: 0.4236 - val_loss: 605.9465 - val_mae: 0.7242 - learning_rate: 0.0100\n",
      "Epoch 80/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 269ms/step - loss: 605.4978 - mae: 0.4230\n",
      "Epoch 80: val_loss improved from 605.94653 to 605.63147, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 189ms/step - loss: 605.4861 - mae: 0.4202 - val_loss: 605.6315 - val_mae: 0.7244 - learning_rate: 0.0100\n",
      "Epoch 81/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 605.1820 - mae: 0.4223\n",
      "Epoch 81: val_loss improved from 605.63147 to 605.31763, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 192ms/step - loss: 605.1703 - mae: 0.4195 - val_loss: 605.3176 - val_mae: 0.7240 - learning_rate: 0.0100\n",
      "Epoch 82/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 604.8701 - mae: 0.4242\n",
      "Epoch 82: val_loss improved from 605.31763 to 605.00507, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 189ms/step - loss: 604.8582 - mae: 0.4212 - val_loss: 605.0051 - val_mae: 0.7232 - learning_rate: 0.0100\n",
      "Epoch 83/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 604.5609 - mae: 0.4277\n",
      "Epoch 83: val_loss improved from 605.00507 to 604.69342, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 604.5486 - mae: 0.4244 - val_loss: 604.6934 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 84/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 604.2527 - mae: 0.4313\n",
      "Epoch 84: val_loss improved from 604.69342 to 604.38245, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 189ms/step - loss: 604.2401 - mae: 0.4278 - val_loss: 604.3824 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 85/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 603.9441 - mae: 0.4339\n",
      "Epoch 85: val_loss improved from 604.38245 to 604.07178, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 603.9313 - mae: 0.4302 - val_loss: 604.0718 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 86/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 603.6340 - mae: 0.4345\n",
      "Epoch 86: val_loss improved from 604.07178 to 603.76154, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 603.6212 - mae: 0.4308 - val_loss: 603.7615 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 87/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 603.3227 - mae: 0.4334\n",
      "Epoch 87: val_loss improved from 603.76154 to 603.45178, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 603.3101 - mae: 0.4298 - val_loss: 603.4518 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 88/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 603.0110 - mae: 0.4312\n",
      "Epoch 88: val_loss improved from 603.45178 to 603.14294, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 602.9986 - mae: 0.4278 - val_loss: 603.1429 - val_mae: 0.7229 - learning_rate: 0.0100\n",
      "Epoch 89/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 602.7001 - mae: 0.4291\n",
      "Epoch 89: val_loss improved from 603.14294 to 602.83502, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 602.6879 - mae: 0.4258 - val_loss: 602.8350 - val_mae: 0.7232 - learning_rate: 0.0100\n",
      "Epoch 90/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 602.3909 - mae: 0.4276\n",
      "Epoch 90: val_loss improved from 602.83502 to 602.52832, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 602.3789 - mae: 0.4244 - val_loss: 602.5283 - val_mae: 0.7233 - learning_rate: 0.0100\n",
      "Epoch 91/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 602.0837 - mae: 0.4273\n",
      "Epoch 91: val_loss improved from 602.52832 to 602.22247, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 602.0718 - mae: 0.4241 - val_loss: 602.2225 - val_mae: 0.7232 - learning_rate: 0.0100\n",
      "Epoch 92/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 601.7786 - mae: 0.4280\n",
      "Epoch 92: val_loss improved from 602.22247 to 601.91766, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 188ms/step - loss: 601.7666 - mae: 0.4247 - val_loss: 601.9177 - val_mae: 0.7229 - learning_rate: 0.0100\n",
      "Epoch 93/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 601.4750 - mae: 0.4293\n",
      "Epoch 93: val_loss improved from 601.91766 to 601.61365, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 601.4629 - mae: 0.4260 - val_loss: 601.6136 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 94/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 601.1723 - mae: 0.4306\n",
      "Epoch 94: val_loss improved from 601.61365 to 601.31030, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 601.1600 - mae: 0.4272 - val_loss: 601.3103 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 95/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 600.8698 - mae: 0.4315\n",
      "Epoch 95: val_loss improved from 601.31030 to 601.00757, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 600.8574 - mae: 0.4280 - val_loss: 601.0076 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 96/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 600.5672 - mae: 0.4317\n",
      "Epoch 96: val_loss improved from 601.00757 to 600.70551, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 600.5549 - mae: 0.4282 - val_loss: 600.7055 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 97/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 600.2648 - mae: 0.4312\n",
      "Epoch 97: val_loss improved from 600.70551 to 600.40405, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 600.2525 - mae: 0.4278 - val_loss: 600.4041 - val_mae: 0.7227 - learning_rate: 0.0100\n",
      "Epoch 98/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 599.9626 - mae: 0.4304\n",
      "Epoch 98: val_loss improved from 600.40405 to 600.10352, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 599.9504 - mae: 0.4270 - val_loss: 600.1035 - val_mae: 0.7228 - learning_rate: 0.0100\n",
      "Epoch 99/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 599.6613 - mae: 0.4297\n",
      "Epoch 99: val_loss improved from 600.10352 to 599.80377, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 188ms/step - loss: 599.6492 - mae: 0.4263 - val_loss: 599.8038 - val_mae: 0.7229 - learning_rate: 0.0100\n",
      "Epoch 100/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 599.3611 - mae: 0.4292\n",
      "Epoch 100: val_loss improved from 599.80377 to 599.50488, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 599.3491 - mae: 0.4259 - val_loss: 599.5049 - val_mae: 0.7229 - learning_rate: 0.0100\n",
      "Epoch 101/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 599.0622 - mae: 0.4292\n",
      "Epoch 101: val_loss improved from 599.50488 to 599.20679, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 599.0502 - mae: 0.4259 - val_loss: 599.2068 - val_mae: 0.7228 - learning_rate: 0.0100\n",
      "Epoch 102/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 598.7645 - mae: 0.4296\n",
      "Epoch 102: val_loss improved from 599.20679 to 598.90967, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 598.7525 - mae: 0.4262 - val_loss: 598.9097 - val_mae: 0.7227 - learning_rate: 0.0100\n",
      "Epoch 103/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 598.4678 - mae: 0.4301\n",
      "Epoch 103: val_loss improved from 598.90967 to 598.61316, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 598.4558 - mae: 0.4267 - val_loss: 598.6132 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 104/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 598.1718 - mae: 0.4306\n",
      "Epoch 104: val_loss improved from 598.61316 to 598.31738, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 598.1597 - mae: 0.4272 - val_loss: 598.3174 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 105/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 597.8762 - mae: 0.4308\n",
      "Epoch 105: val_loss improved from 598.31738 to 598.02222, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 597.8642 - mae: 0.4274 - val_loss: 598.0222 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 106/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 597.5811 - mae: 0.4308\n",
      "Epoch 106: val_loss improved from 598.02222 to 597.72784, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 597.5691 - mae: 0.4274 - val_loss: 597.7278 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 107/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 597.2865 - mae: 0.4306\n",
      "Epoch 107: val_loss improved from 597.72784 to 597.43408, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 597.2745 - mae: 0.4272 - val_loss: 597.4341 - val_mae: 0.7227 - learning_rate: 0.0100\n",
      "Epoch 108/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 596.9924 - mae: 0.4303\n",
      "Epoch 108: val_loss improved from 597.43408 to 597.14111, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 596.9805 - mae: 0.4269 - val_loss: 597.1411 - val_mae: 0.7227 - learning_rate: 0.0100\n",
      "Epoch 109/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 596.6993 - mae: 0.4301\n",
      "Epoch 109: val_loss improved from 597.14111 to 596.84888, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 596.6874 - mae: 0.4267 - val_loss: 596.8489 - val_mae: 0.7228 - learning_rate: 0.0100\n",
      "Epoch 110/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 596.4070 - mae: 0.4300\n",
      "Epoch 110: val_loss improved from 596.84888 to 596.55750, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 189ms/step - loss: 596.3951 - mae: 0.4266 - val_loss: 596.5575 - val_mae: 0.7227 - learning_rate: 0.0100\n",
      "Epoch 111/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 596.1156 - mae: 0.4301\n",
      "Epoch 111: val_loss improved from 596.55750 to 596.26678, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 596.1038 - mae: 0.4267 - val_loss: 596.2668 - val_mae: 0.7227 - learning_rate: 0.0100\n",
      "Epoch 112/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 595.8251 - mae: 0.4303\n",
      "Epoch 112: val_loss improved from 596.26678 to 595.97681, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 595.8133 - mae: 0.4269 - val_loss: 595.9768 - val_mae: 0.7227 - learning_rate: 0.0100\n",
      "Epoch 113/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 595.5353 - mae: 0.4305\n",
      "Epoch 113: val_loss improved from 595.97681 to 595.68750, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 595.5234 - mae: 0.4271 - val_loss: 595.6875 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 114/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 595.2462 - mae: 0.4306\n",
      "Epoch 114: val_loss improved from 595.68750 to 595.39880, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 595.2343 - mae: 0.4272 - val_loss: 595.3988 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 115/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 594.9575 - mae: 0.4307\n",
      "Epoch 115: val_loss improved from 595.39880 to 595.11090, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 594.9457 - mae: 0.4273 - val_loss: 595.1109 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 116/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 594.6696 - mae: 0.4306\n",
      "Epoch 116: val_loss improved from 595.11090 to 594.82361, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 594.6578 - mae: 0.4272 - val_loss: 594.8236 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 117/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 594.3822 - mae: 0.4305\n",
      "Epoch 117: val_loss improved from 594.82361 to 594.53711, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 594.3704 - mae: 0.4272 - val_loss: 594.5371 - val_mae: 0.7227 - learning_rate: 0.0100\n",
      "Epoch 118/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 594.0956 - mae: 0.4305\n",
      "Epoch 118: val_loss improved from 594.53711 to 594.25110, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 594.0838 - mae: 0.4271 - val_loss: 594.2511 - val_mae: 0.7227 - learning_rate: 0.0100\n",
      "Epoch 119/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 593.8096 - mae: 0.4304\n",
      "Epoch 119: val_loss improved from 594.25110 to 593.96594, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 593.7979 - mae: 0.4270 - val_loss: 593.9659 - val_mae: 0.7227 - learning_rate: 0.0100\n",
      "Epoch 120/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 593.5244 - mae: 0.4304\n",
      "Epoch 120: val_loss improved from 593.96594 to 593.68140, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 593.5127 - mae: 0.4271 - val_loss: 593.6814 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 121/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 593.2400 - mae: 0.4305\n",
      "Epoch 121: val_loss improved from 593.68140 to 593.39758, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 593.2283 - mae: 0.4271 - val_loss: 593.3976 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 122/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 592.9562 - mae: 0.4306\n",
      "Epoch 122: val_loss improved from 593.39758 to 593.11438, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 592.9445 - mae: 0.4272 - val_loss: 593.1144 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 123/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 592.6731 - mae: 0.4307\n",
      "Epoch 123: val_loss improved from 593.11438 to 592.83179, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 592.6614 - mae: 0.4273 - val_loss: 592.8318 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 124/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 592.3906 - mae: 0.4307\n",
      "Epoch 124: val_loss improved from 592.83179 to 592.54993, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 592.3788 - mae: 0.4273 - val_loss: 592.5499 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 125/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 592.1086 - mae: 0.4307\n",
      "Epoch 125: val_loss improved from 592.54993 to 592.26862, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 195ms/step - loss: 592.0970 - mae: 0.4273 - val_loss: 592.2686 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 126/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 591.8274 - mae: 0.4307\n",
      "Epoch 126: val_loss improved from 592.26862 to 591.98798, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 591.8157 - mae: 0.4273 - val_loss: 591.9880 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 127/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 591.5467 - mae: 0.4307\n",
      "Epoch 127: val_loss improved from 591.98798 to 591.70801, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 591.5351 - mae: 0.4273 - val_loss: 591.7080 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 128/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 591.2667 - mae: 0.4307\n",
      "Epoch 128: val_loss improved from 591.70801 to 591.42865, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 591.2551 - mae: 0.4273 - val_loss: 591.4286 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 129/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 590.9874 - mae: 0.4307\n",
      "Epoch 129: val_loss improved from 591.42865 to 591.14990, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 190ms/step - loss: 590.9758 - mae: 0.4273 - val_loss: 591.1499 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 130/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 255ms/step - loss: 590.7086 - mae: 0.4307\n",
      "Epoch 130: val_loss improved from 591.14990 to 590.87183, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 590.6970 - mae: 0.4273 - val_loss: 590.8718 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 131/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 590.4306 - mae: 0.4308\n",
      "Epoch 131: val_loss improved from 590.87183 to 590.59424, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 590.4191 - mae: 0.4274 - val_loss: 590.5942 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 132/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 590.1531 - mae: 0.4308\n",
      "Epoch 132: val_loss improved from 590.59424 to 590.31738, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 590.1416 - mae: 0.4274 - val_loss: 590.3174 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 133/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 589.8763 - mae: 0.4309\n",
      "Epoch 133: val_loss improved from 590.31738 to 590.04114, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 193ms/step - loss: 589.8647 - mae: 0.4275 - val_loss: 590.0411 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 134/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 589.6000 - mae: 0.4309\n",
      "Epoch 134: val_loss improved from 590.04114 to 589.76538, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 194ms/step - loss: 589.5884 - mae: 0.4275 - val_loss: 589.7654 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 135/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 589.3243 - mae: 0.4309\n",
      "Epoch 135: val_loss improved from 589.76538 to 589.49036, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 589.3128 - mae: 0.4275 - val_loss: 589.4904 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 136/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 589.0493 - mae: 0.4309\n",
      "Epoch 136: val_loss improved from 589.49036 to 589.21582, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 589.0377 - mae: 0.4275 - val_loss: 589.2158 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 137/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 588.7748 - mae: 0.4309\n",
      "Epoch 137: val_loss improved from 589.21582 to 588.94189, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 588.7633 - mae: 0.4275 - val_loss: 588.9419 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 138/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 588.5008 - mae: 0.4309\n",
      "Epoch 138: val_loss improved from 588.94189 to 588.66858, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 588.4893 - mae: 0.4275 - val_loss: 588.6686 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 139/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 588.2275 - mae: 0.4309\n",
      "Epoch 139: val_loss improved from 588.66858 to 588.39581, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 588.2161 - mae: 0.4275 - val_loss: 588.3958 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 140/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 587.9548 - mae: 0.4310\n",
      "Epoch 140: val_loss improved from 588.39581 to 588.12366, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 587.9434 - mae: 0.4276 - val_loss: 588.1237 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 141/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 587.6826 - mae: 0.4310\n",
      "Epoch 141: val_loss improved from 588.12366 to 587.85205, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 587.6712 - mae: 0.4276 - val_loss: 587.8521 - val_mae: 0.7226 - learning_rate: 0.0100\n",
      "Epoch 142/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 587.4111 - mae: 0.4310\n",
      "Epoch 142: val_loss improved from 587.85205 to 587.58099, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 191ms/step - loss: 587.3997 - mae: 0.4276 - val_loss: 587.5810 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 143/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 587.1400 - mae: 0.4310\n",
      "Epoch 143: val_loss improved from 587.58099 to 587.31042, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 587.1286 - mae: 0.4276 - val_loss: 587.3104 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 144/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 586.8695 - mae: 0.4310\n",
      "Epoch 144: val_loss improved from 587.31042 to 587.04053, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 188ms/step - loss: 586.8581 - mae: 0.4276 - val_loss: 587.0405 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 145/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 586.5995 - mae: 0.4310\n",
      "Epoch 145: val_loss improved from 587.04053 to 586.77112, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 586.5882 - mae: 0.4276 - val_loss: 586.7711 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 146/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 586.3301 - mae: 0.4310\n",
      "Epoch 146: val_loss improved from 586.77112 to 586.50226, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 586.3188 - mae: 0.4276 - val_loss: 586.5023 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 147/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 586.0613 - mae: 0.4311\n",
      "Epoch 147: val_loss improved from 586.50226 to 586.23395, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 586.0500 - mae: 0.4277 - val_loss: 586.2339 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 148/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 585.7931 - mae: 0.4311\n",
      "Epoch 148: val_loss improved from 586.23395 to 585.96619, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 188ms/step - loss: 585.7818 - mae: 0.4277 - val_loss: 585.9662 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 149/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 585.5253 - mae: 0.4311\n",
      "Epoch 149: val_loss improved from 585.96619 to 585.69897, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 585.5140 - mae: 0.4277 - val_loss: 585.6990 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 150/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 585.2581 - mae: 0.4311\n",
      "Epoch 150: val_loss improved from 585.69897 to 585.43225, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 585.2468 - mae: 0.4277 - val_loss: 585.4323 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 151/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 584.9915 - mae: 0.4312\n",
      "Epoch 151: val_loss improved from 585.43225 to 585.16602, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 584.9802 - mae: 0.4278 - val_loss: 585.1660 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 152/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 584.7252 - mae: 0.4312\n",
      "Epoch 152: val_loss improved from 585.16602 to 584.90033, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 584.7139 - mae: 0.4278 - val_loss: 584.9003 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 153/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 584.4595 - mae: 0.4312\n",
      "Epoch 153: val_loss improved from 584.90033 to 584.63513, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 584.4482 - mae: 0.4278 - val_loss: 584.6351 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 154/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 584.1943 - mae: 0.4312\n",
      "Epoch 154: val_loss improved from 584.63513 to 584.37048, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 584.1830 - mae: 0.4278 - val_loss: 584.3705 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 155/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 583.9298 - mae: 0.4312\n",
      "Epoch 155: val_loss improved from 584.37048 to 584.10632, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 583.9185 - mae: 0.4278 - val_loss: 584.1063 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 156/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 583.6655 - mae: 0.4312\n",
      "Epoch 156: val_loss improved from 584.10632 to 583.84265, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 583.6543 - mae: 0.4278 - val_loss: 583.8427 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 157/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 583.4019 - mae: 0.4313\n",
      "Epoch 157: val_loss improved from 583.84265 to 583.57947, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 583.3907 - mae: 0.4279 - val_loss: 583.5795 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 158/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 583.1388 - mae: 0.4313\n",
      "Epoch 158: val_loss improved from 583.57947 to 583.31689, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 583.1276 - mae: 0.4279 - val_loss: 583.3169 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 159/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 582.8761 - mae: 0.4313\n",
      "Epoch 159: val_loss improved from 583.31689 to 583.05469, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 582.8649 - mae: 0.4279 - val_loss: 583.0547 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 160/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 582.6140 - mae: 0.4313\n",
      "Epoch 160: val_loss improved from 583.05469 to 582.79297, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 582.6028 - mae: 0.4279 - val_loss: 582.7930 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 161/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 582.3523 - mae: 0.4313\n",
      "Epoch 161: val_loss improved from 582.79297 to 582.53174, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 582.3411 - mae: 0.4279 - val_loss: 582.5317 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 162/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 582.0911 - mae: 0.4313\n",
      "Epoch 162: val_loss improved from 582.53174 to 582.27100, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 582.0799 - mae: 0.4279 - val_loss: 582.2710 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 163/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 581.8304 - mae: 0.4314\n",
      "Epoch 163: val_loss improved from 582.27100 to 582.01074, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 581.8192 - mae: 0.4280 - val_loss: 582.0107 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 164/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 581.5701 - mae: 0.4314\n",
      "Epoch 164: val_loss improved from 582.01074 to 581.75098, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 581.5589 - mae: 0.4280 - val_loss: 581.7510 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 165/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 581.3103 - mae: 0.4314\n",
      "Epoch 165: val_loss improved from 581.75098 to 581.49164, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 581.2991 - mae: 0.4280 - val_loss: 581.4916 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 166/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 581.0510 - mae: 0.4314\n",
      "Epoch 166: val_loss improved from 581.49164 to 581.23273, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 176ms/step - loss: 581.0399 - mae: 0.4280 - val_loss: 581.2327 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 167/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 580.7921 - mae: 0.4315\n",
      "Epoch 167: val_loss improved from 581.23273 to 580.97430, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 580.7809 - mae: 0.4280 - val_loss: 580.9743 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 168/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 164ms/step - loss: 580.5338 - mae: 0.4315\n",
      "Epoch 168: val_loss improved from 580.97430 to 580.71637, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 580.5226 - mae: 0.4280 - val_loss: 580.7164 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 169/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 580.2758 - mae: 0.4315\n",
      "Epoch 169: val_loss improved from 580.71637 to 580.45886, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 580.2647 - mae: 0.4281 - val_loss: 580.4589 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 170/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 252ms/step - loss: 580.0183 - mae: 0.4315\n",
      "Epoch 170: val_loss improved from 580.45886 to 580.20178, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 580.0072 - mae: 0.4281 - val_loss: 580.2018 - val_mae: 0.7225 - learning_rate: 0.0100\n",
      "Epoch 171/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 579.7612 - mae: 0.4315\n",
      "Epoch 171: val_loss improved from 580.20178 to 579.94513, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 579.7502 - mae: 0.4281 - val_loss: 579.9451 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 172/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 579.5046 - mae: 0.4315\n",
      "Epoch 172: val_loss improved from 579.94513 to 579.68896, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 579.4936 - mae: 0.4281 - val_loss: 579.6890 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 173/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 579.2485 - mae: 0.4316\n",
      "Epoch 173: val_loss improved from 579.68896 to 579.43323, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 579.2374 - mae: 0.4281 - val_loss: 579.4332 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 174/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 578.9927 - mae: 0.4316\n",
      "Epoch 174: val_loss improved from 579.43323 to 579.17786, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 578.9817 - mae: 0.4282 - val_loss: 579.1779 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 175/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 578.7374 - mae: 0.4316\n",
      "Epoch 175: val_loss improved from 579.17786 to 578.92297, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 578.7263 - mae: 0.4282 - val_loss: 578.9230 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 176/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 578.4825 - mae: 0.4316\n",
      "Epoch 176: val_loss improved from 578.92297 to 578.66846, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 191ms/step - loss: 578.4715 - mae: 0.4282 - val_loss: 578.6685 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 177/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 578.2280 - mae: 0.4316\n",
      "Epoch 177: val_loss improved from 578.66846 to 578.41443, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 578.2170 - mae: 0.4282 - val_loss: 578.4144 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 178/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 577.9740 - mae: 0.4316\n",
      "Epoch 178: val_loss improved from 578.41443 to 578.16083, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 577.9630 - mae: 0.4282 - val_loss: 578.1608 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 179/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 577.7205 - mae: 0.4316\n",
      "Epoch 179: val_loss improved from 578.16083 to 577.90759, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 577.7094 - mae: 0.4282 - val_loss: 577.9076 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 180/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 577.4672 - mae: 0.4317\n",
      "Epoch 180: val_loss improved from 577.90759 to 577.65479, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 577.4562 - mae: 0.4283 - val_loss: 577.6548 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 181/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 577.2144 - mae: 0.4317\n",
      "Epoch 181: val_loss improved from 577.65479 to 577.40240, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 577.2034 - mae: 0.4283 - val_loss: 577.4024 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 182/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 576.9620 - mae: 0.4317\n",
      "Epoch 182: val_loss improved from 577.40240 to 577.15039, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 576.9510 - mae: 0.4283 - val_loss: 577.1504 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 183/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 576.7101 - mae: 0.4317\n",
      "Epoch 183: val_loss improved from 577.15039 to 576.89880, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 576.6992 - mae: 0.4283 - val_loss: 576.8988 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 184/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 576.4585 - mae: 0.4317\n",
      "Epoch 184: val_loss improved from 576.89880 to 576.64764, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 576.4476 - mae: 0.4283 - val_loss: 576.6476 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 185/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 576.2073 - mae: 0.4317\n",
      "Epoch 185: val_loss improved from 576.64764 to 576.39685, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 576.1964 - mae: 0.4283 - val_loss: 576.3969 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 186/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 575.9565 - mae: 0.4318\n",
      "Epoch 186: val_loss improved from 576.39685 to 576.14642, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 575.9456 - mae: 0.4283 - val_loss: 576.1464 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 187/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 575.7062 - mae: 0.4318\n",
      "Epoch 187: val_loss improved from 576.14642 to 575.89636, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 179ms/step - loss: 575.6953 - mae: 0.4284 - val_loss: 575.8964 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 188/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 575.4561 - mae: 0.4318\n",
      "Epoch 188: val_loss improved from 575.89636 to 575.64673, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 188ms/step - loss: 575.4451 - mae: 0.4284 - val_loss: 575.6467 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 189/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 575.2065 - mae: 0.4318\n",
      "Epoch 189: val_loss improved from 575.64673 to 575.39746, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 575.1956 - mae: 0.4284 - val_loss: 575.3975 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 190/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 574.9573 - mae: 0.4318\n",
      "Epoch 190: val_loss improved from 575.39746 to 575.14862, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 574.9464 - mae: 0.4284 - val_loss: 575.1486 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 191/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 574.7084 - mae: 0.4319\n",
      "Epoch 191: val_loss improved from 575.14862 to 574.90009, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 574.6976 - mae: 0.4284 - val_loss: 574.9001 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 192/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 574.4600 - mae: 0.4319\n",
      "Epoch 192: val_loss improved from 574.90009 to 574.65204, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 574.4491 - mae: 0.4285 - val_loss: 574.6520 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 193/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 574.2119 - mae: 0.4319\n",
      "Epoch 193: val_loss improved from 574.65204 to 574.40430, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 574.2010 - mae: 0.4285 - val_loss: 574.4043 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 194/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 573.9641 - mae: 0.4319\n",
      "Epoch 194: val_loss improved from 574.40430 to 574.15692, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 573.9532 - mae: 0.4285 - val_loss: 574.1569 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 195/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 573.7167 - mae: 0.4319\n",
      "Epoch 195: val_loss improved from 574.15692 to 573.90991, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 573.7059 - mae: 0.4285 - val_loss: 573.9099 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 196/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 573.4697 - mae: 0.4319\n",
      "Epoch 196: val_loss improved from 573.90991 to 573.66321, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 573.4589 - mae: 0.4285 - val_loss: 573.6632 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 197/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 573.2231 - mae: 0.4320\n",
      "Epoch 197: val_loss improved from 573.66321 to 573.41699, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 573.2123 - mae: 0.4285 - val_loss: 573.4170 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 198/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 572.9769 - mae: 0.4320\n",
      "Epoch 198: val_loss improved from 573.41699 to 573.17102, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 572.9661 - mae: 0.4285 - val_loss: 573.1710 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 199/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 572.7310 - mae: 0.4320\n",
      "Epoch 199: val_loss improved from 573.17102 to 572.92542, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 572.7202 - mae: 0.4286 - val_loss: 572.9254 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 200/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 572.4854 - mae: 0.4320\n",
      "Epoch 200: val_loss improved from 572.92542 to 572.68018, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 572.4745 - mae: 0.4286 - val_loss: 572.6802 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 201/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 572.2401 - mae: 0.4320\n",
      "Epoch 201: val_loss improved from 572.68018 to 572.43536, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 177ms/step - loss: 572.2293 - mae: 0.4286 - val_loss: 572.4354 - val_mae: 0.7224 - learning_rate: 0.0100\n",
      "Epoch 202/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 272ms/step - loss: 571.9953 - mae: 0.4320\n",
      "Epoch 202: val_loss improved from 572.43536 to 572.19080, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 571.9845 - mae: 0.4286 - val_loss: 572.1908 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 203/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 571.7508 - mae: 0.4320\n",
      "Epoch 203: val_loss improved from 572.19080 to 571.94666, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 571.7400 - mae: 0.4286 - val_loss: 571.9467 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 204/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 571.5066 - mae: 0.4321\n",
      "Epoch 204: val_loss improved from 571.94666 to 571.70276, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 571.4958 - mae: 0.4286 - val_loss: 571.7028 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 205/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 571.2628 - mae: 0.4321\n",
      "Epoch 205: val_loss improved from 571.70276 to 571.45929, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 571.2520 - mae: 0.4287 - val_loss: 571.4593 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 206/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 571.0193 - mae: 0.4321\n",
      "Epoch 206: val_loss improved from 571.45929 to 571.21613, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 571.0085 - mae: 0.4287 - val_loss: 571.2161 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 207/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 570.7761 - mae: 0.4321\n",
      "Epoch 207: val_loss improved from 571.21613 to 570.97327, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 570.7654 - mae: 0.4287 - val_loss: 570.9733 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 208/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 570.5333 - mae: 0.4321\n",
      "Epoch 208: val_loss improved from 570.97327 to 570.73083, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 570.5226 - mae: 0.4287 - val_loss: 570.7308 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 209/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 570.2909 - mae: 0.4321\n",
      "Epoch 209: val_loss improved from 570.73083 to 570.48865, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 570.2802 - mae: 0.4287 - val_loss: 570.4886 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 210/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 570.0487 - mae: 0.4322\n",
      "Epoch 210: val_loss improved from 570.48865 to 570.24683, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 570.0380 - mae: 0.4287 - val_loss: 570.2468 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 211/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 569.8069 - mae: 0.4322\n",
      "Epoch 211: val_loss improved from 570.24683 to 570.00531, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 569.7962 - mae: 0.4287 - val_loss: 570.0053 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 212/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 569.5654 - mae: 0.4322\n",
      "Epoch 212: val_loss improved from 570.00531 to 569.76416, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 569.5547 - mae: 0.4288 - val_loss: 569.7642 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 213/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - loss: 569.3242 - mae: 0.4322\n",
      "Epoch 213: val_loss improved from 569.76416 to 569.52325, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 569.3135 - mae: 0.4288 - val_loss: 569.5233 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 214/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 569.0834 - mae: 0.4322\n",
      "Epoch 214: val_loss improved from 569.52325 to 569.28271, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 569.0727 - mae: 0.4288 - val_loss: 569.2827 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 215/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 568.8429 - mae: 0.4322\n",
      "Epoch 215: val_loss improved from 569.28271 to 569.04248, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 568.8322 - mae: 0.4288 - val_loss: 569.0425 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 216/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 568.6027 - mae: 0.4323\n",
      "Epoch 216: val_loss improved from 569.04248 to 568.80255, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 568.5920 - mae: 0.4288 - val_loss: 568.8026 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 217/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 568.3627 - mae: 0.4323\n",
      "Epoch 217: val_loss improved from 568.80255 to 568.56299, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 568.3521 - mae: 0.4288 - val_loss: 568.5630 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 218/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 568.1232 - mae: 0.4323\n",
      "Epoch 218: val_loss improved from 568.56299 to 568.32367, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 568.1125 - mae: 0.4289 - val_loss: 568.3237 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 219/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 567.8839 - mae: 0.4323\n",
      "Epoch 219: val_loss improved from 568.32367 to 568.08466, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 567.8732 - mae: 0.4289 - val_loss: 568.0847 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 220/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 567.6449 - mae: 0.4323\n",
      "Epoch 220: val_loss improved from 568.08466 to 567.84595, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 179ms/step - loss: 567.6342 - mae: 0.4289 - val_loss: 567.8459 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 221/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 567.4062 - mae: 0.4323\n",
      "Epoch 221: val_loss improved from 567.84595 to 567.60760, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 567.3956 - mae: 0.4289 - val_loss: 567.6076 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 222/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 567.1678 - mae: 0.4324\n",
      "Epoch 222: val_loss improved from 567.60760 to 567.36957, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 567.1572 - mae: 0.4289 - val_loss: 567.3696 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 223/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 566.9298 - mae: 0.4324\n",
      "Epoch 223: val_loss improved from 567.36957 to 567.13177, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 566.9192 - mae: 0.4289 - val_loss: 567.1318 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 224/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 566.6920 - mae: 0.4324\n",
      "Epoch 224: val_loss improved from 567.13177 to 566.89435, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 566.6814 - mae: 0.4289 - val_loss: 566.8943 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 225/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 566.4546 - mae: 0.4324\n",
      "Epoch 225: val_loss improved from 566.89435 to 566.65717, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 566.4440 - mae: 0.4290 - val_loss: 566.6572 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 226/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 566.2175 - mae: 0.4324\n",
      "Epoch 226: val_loss improved from 566.65717 to 566.42029, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 566.2068 - mae: 0.4290 - val_loss: 566.4203 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 227/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 565.9806 - mae: 0.4324\n",
      "Epoch 227: val_loss improved from 566.42029 to 566.18365, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 565.9700 - mae: 0.4290 - val_loss: 566.1837 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 228/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 565.7440 - mae: 0.4324\n",
      "Epoch 228: val_loss improved from 566.18365 to 565.94733, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 565.7333 - mae: 0.4290 - val_loss: 565.9473 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 229/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 565.5077 - mae: 0.4325\n",
      "Epoch 229: val_loss improved from 565.94733 to 565.71130, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 565.4971 - mae: 0.4290 - val_loss: 565.7113 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 230/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 565.2717 - mae: 0.4325\n",
      "Epoch 230: val_loss improved from 565.71130 to 565.47559, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 565.2611 - mae: 0.4290 - val_loss: 565.4756 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 231/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 565.0359 - mae: 0.4325\n",
      "Epoch 231: val_loss improved from 565.47559 to 565.24023, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 565.0254 - mae: 0.4290 - val_loss: 565.2402 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 232/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 564.8006 - mae: 0.4325\n",
      "Epoch 232: val_loss improved from 565.24023 to 565.00500, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 564.7900 - mae: 0.4291 - val_loss: 565.0050 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 233/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 564.5654 - mae: 0.4325\n",
      "Epoch 233: val_loss improved from 565.00500 to 564.77014, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 564.5549 - mae: 0.4291 - val_loss: 564.7701 - val_mae: 0.7223 - learning_rate: 0.0100\n",
      "Epoch 234/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 564.3306 - mae: 0.4325\n",
      "Epoch 234: val_loss improved from 564.77014 to 564.53552, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 564.3200 - mae: 0.4291 - val_loss: 564.5355 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 235/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 564.0959 - mae: 0.4326\n",
      "Epoch 235: val_loss improved from 564.53552 to 564.30127, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 564.0854 - mae: 0.4291 - val_loss: 564.3013 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 236/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 563.8617 - mae: 0.4326\n",
      "Epoch 236: val_loss improved from 564.30127 to 564.06720, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 563.8511 - mae: 0.4291 - val_loss: 564.0672 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 237/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 563.6276 - mae: 0.4326\n",
      "Epoch 237: val_loss improved from 564.06720 to 563.83344, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 179ms/step - loss: 563.6171 - mae: 0.4291 - val_loss: 563.8334 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 238/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 563.3939 - mae: 0.4326\n",
      "Epoch 238: val_loss improved from 563.83344 to 563.59991, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 563.3834 - mae: 0.4292 - val_loss: 563.5999 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 239/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 563.1604 - mae: 0.4326\n",
      "Epoch 239: val_loss improved from 563.59991 to 563.36670, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 188ms/step - loss: 563.1498 - mae: 0.4292 - val_loss: 563.3667 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 240/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 562.9272 - mae: 0.4326\n",
      "Epoch 240: val_loss improved from 563.36670 to 563.13379, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 562.9166 - mae: 0.4292 - val_loss: 563.1338 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 241/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 562.6943 - mae: 0.4326\n",
      "Epoch 241: val_loss improved from 563.13379 to 562.90112, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 562.6838 - mae: 0.4292 - val_loss: 562.9011 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 242/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 562.4616 - mae: 0.4327\n",
      "Epoch 242: val_loss improved from 562.90112 to 562.66864, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 562.4510 - mae: 0.4292 - val_loss: 562.6686 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 243/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 562.2292 - mae: 0.4327\n",
      "Epoch 243: val_loss improved from 562.66864 to 562.43646, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 562.2186 - mae: 0.4292 - val_loss: 562.4365 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 244/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 561.9970 - mae: 0.4327\n",
      "Epoch 244: val_loss improved from 562.43646 to 562.20459, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 561.9865 - mae: 0.4293 - val_loss: 562.2046 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 245/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 561.7651 - mae: 0.4327\n",
      "Epoch 245: val_loss improved from 562.20459 to 561.97296, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 561.7546 - mae: 0.4293 - val_loss: 561.9730 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 246/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 561.5336 - mae: 0.4327\n",
      "Epoch 246: val_loss improved from 561.97296 to 561.74158, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 178ms/step - loss: 561.5231 - mae: 0.4293 - val_loss: 561.7416 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 247/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 561.3022 - mae: 0.4327\n",
      "Epoch 247: val_loss improved from 561.74158 to 561.51050, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 561.2917 - mae: 0.4293 - val_loss: 561.5105 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 248/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 561.0711 - mae: 0.4327\n",
      "Epoch 248: val_loss improved from 561.51050 to 561.27966, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 561.0606 - mae: 0.4293 - val_loss: 561.2797 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 249/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 560.8403 - mae: 0.4328\n",
      "Epoch 249: val_loss improved from 561.27966 to 561.04907, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 560.8298 - mae: 0.4293 - val_loss: 561.0491 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 250/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 560.6097 - mae: 0.4328\n",
      "Epoch 250: val_loss improved from 561.04907 to 560.81873, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 560.5992 - mae: 0.4293 - val_loss: 560.8187 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 251/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 560.3793 - mae: 0.4328\n",
      "Epoch 251: val_loss improved from 560.81873 to 560.58862, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 560.3689 - mae: 0.4294 - val_loss: 560.5886 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 252/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 560.1493 - mae: 0.4328\n",
      "Epoch 252: val_loss improved from 560.58862 to 560.35876, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 189ms/step - loss: 560.1389 - mae: 0.4294 - val_loss: 560.3588 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 253/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 274ms/step - loss: 559.9194 - mae: 0.4328\n",
      "Epoch 253: val_loss improved from 560.35876 to 560.12927, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 559.9090 - mae: 0.4294 - val_loss: 560.1293 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 254/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 559.6899 - mae: 0.4328\n",
      "Epoch 254: val_loss improved from 560.12927 to 559.89990, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 559.6795 - mae: 0.4294 - val_loss: 559.8999 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 255/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 559.4606 - mae: 0.4328\n",
      "Epoch 255: val_loss improved from 559.89990 to 559.67078, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 559.4501 - mae: 0.4294 - val_loss: 559.6708 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 256/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 559.2314 - mae: 0.4329\n",
      "Epoch 256: val_loss improved from 559.67078 to 559.44189, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 559.2210 - mae: 0.4294 - val_loss: 559.4419 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 257/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 559.0026 - mae: 0.4329\n",
      "Epoch 257: val_loss improved from 559.44189 to 559.21332, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 558.9922 - mae: 0.4294 - val_loss: 559.2133 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 258/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 558.7740 - mae: 0.4329\n",
      "Epoch 258: val_loss improved from 559.21332 to 558.98499, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 558.7636 - mae: 0.4295 - val_loss: 558.9850 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 259/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 558.5457 - mae: 0.4329\n",
      "Epoch 259: val_loss improved from 558.98499 to 558.75684, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 558.5353 - mae: 0.4295 - val_loss: 558.7568 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 260/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 558.3176 - mae: 0.4329\n",
      "Epoch 260: val_loss improved from 558.75684 to 558.52893, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 558.3072 - mae: 0.4295 - val_loss: 558.5289 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 261/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 558.0897 - mae: 0.4329\n",
      "Epoch 261: val_loss improved from 558.52893 to 558.30127, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 558.0793 - mae: 0.4295 - val_loss: 558.3013 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 262/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 557.8621 - mae: 0.4330\n",
      "Epoch 262: val_loss improved from 558.30127 to 558.07397, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 557.8516 - mae: 0.4295 - val_loss: 558.0740 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 263/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 557.6348 - mae: 0.4330\n",
      "Epoch 263: val_loss improved from 558.07397 to 557.84680, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 557.6243 - mae: 0.4295 - val_loss: 557.8468 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 264/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 557.4076 - mae: 0.4330\n",
      "Epoch 264: val_loss improved from 557.84680 to 557.61981, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 188ms/step - loss: 557.3972 - mae: 0.4295 - val_loss: 557.6198 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 265/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 557.1807 - mae: 0.4330\n",
      "Epoch 265: val_loss improved from 557.61981 to 557.39313, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 557.1703 - mae: 0.4296 - val_loss: 557.3931 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 266/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 556.9540 - mae: 0.4330\n",
      "Epoch 266: val_loss improved from 557.39313 to 557.16675, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 556.9436 - mae: 0.4296 - val_loss: 557.1667 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 267/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 556.7275 - mae: 0.4330\n",
      "Epoch 267: val_loss improved from 557.16675 to 556.94049, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 556.7172 - mae: 0.4296 - val_loss: 556.9405 - val_mae: 0.7222 - learning_rate: 0.0100\n",
      "Epoch 268/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 556.5013 - mae: 0.4330\n",
      "Epoch 268: val_loss improved from 556.94049 to 556.71448, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 556.4910 - mae: 0.4296 - val_loss: 556.7145 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 269/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 556.2753 - mae: 0.4331\n",
      "Epoch 269: val_loss improved from 556.71448 to 556.48871, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 556.2650 - mae: 0.4296 - val_loss: 556.4887 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 270/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 556.0496 - mae: 0.4331\n",
      "Epoch 270: val_loss improved from 556.48871 to 556.26318, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 556.0393 - mae: 0.4296 - val_loss: 556.2632 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 271/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 555.8241 - mae: 0.4331\n",
      "Epoch 271: val_loss improved from 556.26318 to 556.03784, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 555.8137 - mae: 0.4296 - val_loss: 556.0378 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 272/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 555.5988 - mae: 0.4331\n",
      "Epoch 272: val_loss improved from 556.03784 to 555.81274, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 555.5884 - mae: 0.4297 - val_loss: 555.8127 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 273/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 555.3737 - mae: 0.4331\n",
      "Epoch 273: val_loss improved from 555.81274 to 555.58789, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 555.3633 - mae: 0.4297 - val_loss: 555.5879 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 274/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 555.1488 - mae: 0.4331\n",
      "Epoch 274: val_loss improved from 555.58789 to 555.36328, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 555.1385 - mae: 0.4297 - val_loss: 555.3633 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 275/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 554.9243 - mae: 0.4332\n",
      "Epoch 275: val_loss improved from 555.36328 to 555.13892, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 554.9139 - mae: 0.4297 - val_loss: 555.1389 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 276/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 554.6998 - mae: 0.4332\n",
      "Epoch 276: val_loss improved from 555.13892 to 554.91467, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 189ms/step - loss: 554.6895 - mae: 0.4297 - val_loss: 554.9147 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 277/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 554.4756 - mae: 0.4332\n",
      "Epoch 277: val_loss improved from 554.91467 to 554.69067, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 554.4653 - mae: 0.4297 - val_loss: 554.6907 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 278/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 554.2517 - mae: 0.4332\n",
      "Epoch 278: val_loss improved from 554.69067 to 554.46692, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 554.2414 - mae: 0.4297 - val_loss: 554.4669 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 279/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 554.0280 - mae: 0.4332\n",
      "Epoch 279: val_loss improved from 554.46692 to 554.24335, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 554.0176 - mae: 0.4297 - val_loss: 554.2433 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 280/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 553.8044 - mae: 0.4332\n",
      "Epoch 280: val_loss improved from 554.24335 to 554.02008, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 553.7941 - mae: 0.4298 - val_loss: 554.0201 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 281/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 553.5811 - mae: 0.4332\n",
      "Epoch 281: val_loss improved from 554.02008 to 553.79700, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 553.5708 - mae: 0.4298 - val_loss: 553.7970 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 282/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 553.3580 - mae: 0.4332\n",
      "Epoch 282: val_loss improved from 553.79700 to 553.57410, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 553.3477 - mae: 0.4298 - val_loss: 553.5741 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 283/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 553.1351 - mae: 0.4333\n",
      "Epoch 283: val_loss improved from 553.57410 to 553.35144, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 553.1249 - mae: 0.4298 - val_loss: 553.3514 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 284/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 552.9125 - mae: 0.4333\n",
      "Epoch 284: val_loss improved from 553.35144 to 553.12891, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 552.9022 - mae: 0.4298 - val_loss: 553.1289 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 285/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 552.6900 - mae: 0.4333\n",
      "Epoch 285: val_loss improved from 553.12891 to 552.90674, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 552.6797 - mae: 0.4298 - val_loss: 552.9067 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 286/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 552.4678 - mae: 0.4333\n",
      "Epoch 286: val_loss improved from 552.90674 to 552.68469, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 552.4575 - mae: 0.4298 - val_loss: 552.6847 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 287/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 552.2458 - mae: 0.4333\n",
      "Epoch 287: val_loss improved from 552.68469 to 552.46283, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 552.2355 - mae: 0.4299 - val_loss: 552.4628 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 288/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 552.0240 - mae: 0.4333\n",
      "Epoch 288: val_loss improved from 552.46283 to 552.24121, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 552.0137 - mae: 0.4299 - val_loss: 552.2412 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 289/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 551.8024 - mae: 0.4333\n",
      "Epoch 289: val_loss improved from 552.24121 to 552.01978, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 551.7921 - mae: 0.4299 - val_loss: 552.0198 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 290/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 551.5809 - mae: 0.4334\n",
      "Epoch 290: val_loss improved from 552.01978 to 551.79858, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 551.5707 - mae: 0.4299 - val_loss: 551.7986 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 291/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 551.3597 - mae: 0.4334\n",
      "Epoch 291: val_loss improved from 551.79858 to 551.57751, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 551.3495 - mae: 0.4299 - val_loss: 551.5775 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 292/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 251ms/step - loss: 551.1387 - mae: 0.4334\n",
      "Epoch 292: val_loss improved from 551.57751 to 551.35681, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 551.1285 - mae: 0.4299 - val_loss: 551.3568 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 293/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 550.9180 - mae: 0.4334\n",
      "Epoch 293: val_loss improved from 551.35681 to 551.13623, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 550.9078 - mae: 0.4299 - val_loss: 551.1362 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 294/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 550.6974 - mae: 0.4334\n",
      "Epoch 294: val_loss improved from 551.13623 to 550.91577, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 550.6871 - mae: 0.4299 - val_loss: 550.9158 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 295/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 173ms/step - loss: 550.4770 - mae: 0.4334\n",
      "Epoch 295: val_loss improved from 550.91577 to 550.69562, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 207ms/step - loss: 550.4668 - mae: 0.4300 - val_loss: 550.6956 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 296/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 550.2568 - mae: 0.4334\n",
      "Epoch 296: val_loss improved from 550.69562 to 550.47559, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 206ms/step - loss: 550.2466 - mae: 0.4300 - val_loss: 550.4756 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 297/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 550.0369 - mae: 0.4335\n",
      "Epoch 297: val_loss improved from 550.47559 to 550.25586, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 192ms/step - loss: 550.0267 - mae: 0.4300 - val_loss: 550.2559 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 298/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - loss: 549.8171 - mae: 0.4335\n",
      "Epoch 298: val_loss improved from 550.25586 to 550.03625, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 189ms/step - loss: 549.8069 - mae: 0.4300 - val_loss: 550.0363 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 299/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 549.5975 - mae: 0.4335\n",
      "Epoch 299: val_loss improved from 550.03625 to 549.81689, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 549.5873 - mae: 0.4300 - val_loss: 549.8169 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 300/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 549.3782 - mae: 0.4335\n",
      "Epoch 300: val_loss improved from 549.81689 to 549.59766, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 549.3680 - mae: 0.4300 - val_loss: 549.5977 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 301/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 549.1589 - mae: 0.4335\n",
      "Epoch 301: val_loss improved from 549.59766 to 549.37866, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 549.1487 - mae: 0.4301 - val_loss: 549.3787 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 302/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 548.9401 - mae: 0.4335\n",
      "Epoch 302: val_loss improved from 549.37866 to 549.15991, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 548.9299 - mae: 0.4301 - val_loss: 549.1599 - val_mae: 0.7221 - learning_rate: 0.0100\n",
      "Epoch 303/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - loss: 548.7213 - mae: 0.4336\n",
      "Epoch 303: val_loss improved from 549.15991 to 548.94128, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 548.7111 - mae: 0.4301 - val_loss: 548.9413 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 304/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 548.5026 - mae: 0.4336\n",
      "Epoch 304: val_loss improved from 548.94128 to 548.72290, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 548.4924 - mae: 0.4301 - val_loss: 548.7229 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 305/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 548.2843 - mae: 0.4336\n",
      "Epoch 305: val_loss improved from 548.72290 to 548.50464, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 548.2741 - mae: 0.4301 - val_loss: 548.5046 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 306/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 548.0660 - mae: 0.4336\n",
      "Epoch 306: val_loss improved from 548.50464 to 548.28668, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 548.0558 - mae: 0.4301 - val_loss: 548.2867 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 307/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 547.8480 - mae: 0.4336\n",
      "Epoch 307: val_loss improved from 548.28668 to 548.06885, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 547.8378 - mae: 0.4301 - val_loss: 548.0688 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 308/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 547.6302 - mae: 0.4336\n",
      "Epoch 308: val_loss improved from 548.06885 to 547.85120, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 547.6201 - mae: 0.4301 - val_loss: 547.8512 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 309/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 547.4126 - mae: 0.4336\n",
      "Epoch 309: val_loss improved from 547.85120 to 547.63379, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 547.4024 - mae: 0.4302 - val_loss: 547.6338 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 310/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 547.1952 - mae: 0.4336\n",
      "Epoch 310: val_loss improved from 547.63379 to 547.41650, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 547.1850 - mae: 0.4302 - val_loss: 547.4165 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 311/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 546.9779 - mae: 0.4337\n",
      "Epoch 311: val_loss improved from 547.41650 to 547.19946, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 191ms/step - loss: 546.9677 - mae: 0.4302 - val_loss: 547.1995 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 312/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 546.7609 - mae: 0.4337\n",
      "Epoch 312: val_loss improved from 547.19946 to 546.98254, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 546.7507 - mae: 0.4302 - val_loss: 546.9825 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 313/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 546.5440 - mae: 0.4337\n",
      "Epoch 313: val_loss improved from 546.98254 to 546.76587, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 546.5338 - mae: 0.4302 - val_loss: 546.7659 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 314/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 546.3273 - mae: 0.4337\n",
      "Epoch 314: val_loss improved from 546.76587 to 546.54932, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 179ms/step - loss: 546.3171 - mae: 0.4302 - val_loss: 546.5493 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 315/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 546.1108 - mae: 0.4337\n",
      "Epoch 315: val_loss improved from 546.54932 to 546.33301, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 546.1006 - mae: 0.4302 - val_loss: 546.3330 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 316/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 545.8945 - mae: 0.4337\n",
      "Epoch 316: val_loss improved from 546.33301 to 546.11682, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 545.8844 - mae: 0.4303 - val_loss: 546.1168 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 317/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 545.6783 - mae: 0.4337\n",
      "Epoch 317: val_loss improved from 546.11682 to 545.90088, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 545.6682 - mae: 0.4303 - val_loss: 545.9009 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 318/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 545.4624 - mae: 0.4337\n",
      "Epoch 318: val_loss improved from 545.90088 to 545.68518, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 545.4523 - mae: 0.4303 - val_loss: 545.6852 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 319/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 545.2467 - mae: 0.4338\n",
      "Epoch 319: val_loss improved from 545.68518 to 545.46960, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 545.2366 - mae: 0.4303 - val_loss: 545.4696 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 320/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 545.0311 - mae: 0.4338\n",
      "Epoch 320: val_loss improved from 545.46960 to 545.25415, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 545.0210 - mae: 0.4303 - val_loss: 545.2542 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 321/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 544.8157 - mae: 0.4338\n",
      "Epoch 321: val_loss improved from 545.25415 to 545.03894, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 544.8056 - mae: 0.4303 - val_loss: 545.0389 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 322/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 544.6005 - mae: 0.4338\n",
      "Epoch 322: val_loss improved from 545.03894 to 544.82385, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 544.5904 - mae: 0.4303 - val_loss: 544.8239 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 323/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 252ms/step - loss: 544.3855 - mae: 0.4338\n",
      "Epoch 323: val_loss improved from 544.82385 to 544.60901, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 544.3754 - mae: 0.4303 - val_loss: 544.6090 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 324/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 544.1706 - mae: 0.4338\n",
      "Epoch 324: val_loss improved from 544.60901 to 544.39435, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 544.1605 - mae: 0.4304 - val_loss: 544.3943 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 325/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 543.9559 - mae: 0.4338\n",
      "Epoch 325: val_loss improved from 544.39435 to 544.17981, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 543.9459 - mae: 0.4304 - val_loss: 544.1798 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 326/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 543.7415 - mae: 0.4339\n",
      "Epoch 326: val_loss improved from 544.17981 to 543.96552, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 543.7314 - mae: 0.4304 - val_loss: 543.9655 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 327/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 543.5272 - mae: 0.4339\n",
      "Epoch 327: val_loss improved from 543.96552 to 543.75134, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 543.5171 - mae: 0.4304 - val_loss: 543.7513 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 328/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 543.3130 - mae: 0.4339\n",
      "Epoch 328: val_loss improved from 543.75134 to 543.53735, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 543.3029 - mae: 0.4304 - val_loss: 543.5374 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 329/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 543.0990 - mae: 0.4339\n",
      "Epoch 329: val_loss improved from 543.53735 to 543.32361, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 543.0889 - mae: 0.4304 - val_loss: 543.3236 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 330/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 542.8853 - mae: 0.4339\n",
      "Epoch 330: val_loss improved from 543.32361 to 543.10999, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 542.8752 - mae: 0.4304 - val_loss: 543.1100 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 331/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 542.6716 - mae: 0.4339\n",
      "Epoch 331: val_loss improved from 543.10999 to 542.89648, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 542.6616 - mae: 0.4305 - val_loss: 542.8965 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 332/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 542.4582 - mae: 0.4339\n",
      "Epoch 332: val_loss improved from 542.89648 to 542.68323, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 542.4481 - mae: 0.4305 - val_loss: 542.6832 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 333/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 542.2449 - mae: 0.4339\n",
      "Epoch 333: val_loss improved from 542.68323 to 542.47009, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 542.2349 - mae: 0.4305 - val_loss: 542.4701 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 334/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 542.0318 - mae: 0.4340\n",
      "Epoch 334: val_loss improved from 542.47009 to 542.25714, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 189ms/step - loss: 542.0217 - mae: 0.4305 - val_loss: 542.2571 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 335/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 541.8188 - mae: 0.4340\n",
      "Epoch 335: val_loss improved from 542.25714 to 542.04437, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 541.8088 - mae: 0.4305 - val_loss: 542.0444 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 336/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 541.6061 - mae: 0.4340\n",
      "Epoch 336: val_loss improved from 542.04437 to 541.83185, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 189ms/step - loss: 541.5961 - mae: 0.4305 - val_loss: 541.8318 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 337/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 541.3936 - mae: 0.4340\n",
      "Epoch 337: val_loss improved from 541.83185 to 541.61938, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 541.3835 - mae: 0.4305 - val_loss: 541.6194 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 338/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 541.1812 - mae: 0.4340\n",
      "Epoch 338: val_loss improved from 541.61938 to 541.40710, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 541.1711 - mae: 0.4305 - val_loss: 541.4071 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 339/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 540.9689 - mae: 0.4340\n",
      "Epoch 339: val_loss improved from 541.40710 to 541.19501, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 540.9588 - mae: 0.4306 - val_loss: 541.1950 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 340/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 540.7568 - mae: 0.4340\n",
      "Epoch 340: val_loss improved from 541.19501 to 540.98309, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 540.7467 - mae: 0.4306 - val_loss: 540.9831 - val_mae: 0.7220 - learning_rate: 0.0100\n",
      "Epoch 341/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 540.5449 - mae: 0.4341\n",
      "Epoch 341: val_loss improved from 540.98309 to 540.77136, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 178ms/step - loss: 540.5349 - mae: 0.4306 - val_loss: 540.7714 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 342/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 540.3332 - mae: 0.4341\n",
      "Epoch 342: val_loss improved from 540.77136 to 540.55981, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 188ms/step - loss: 540.3231 - mae: 0.4306 - val_loss: 540.5598 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 343/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 540.1216 - mae: 0.4341\n",
      "Epoch 343: val_loss improved from 540.55981 to 540.34839, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 540.1116 - mae: 0.4306 - val_loss: 540.3484 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 344/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 539.9102 - mae: 0.4341\n",
      "Epoch 344: val_loss improved from 540.34839 to 540.13708, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 179ms/step - loss: 539.9002 - mae: 0.4306 - val_loss: 540.1371 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 345/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 539.6990 - mae: 0.4341\n",
      "Epoch 345: val_loss improved from 540.13708 to 539.92603, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 539.6890 - mae: 0.4306 - val_loss: 539.9260 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 346/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 539.4879 - mae: 0.4341\n",
      "Epoch 346: val_loss improved from 539.92603 to 539.71509, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 539.4779 - mae: 0.4307 - val_loss: 539.7151 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 347/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 539.2770 - mae: 0.4341\n",
      "Epoch 347: val_loss improved from 539.71509 to 539.50433, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 539.2670 - mae: 0.4307 - val_loss: 539.5043 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 348/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 539.0662 - mae: 0.4341\n",
      "Epoch 348: val_loss improved from 539.50433 to 539.29376, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 189ms/step - loss: 539.0562 - mae: 0.4307 - val_loss: 539.2938 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 349/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 538.8557 - mae: 0.4342\n",
      "Epoch 349: val_loss improved from 539.29376 to 539.08331, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 538.8457 - mae: 0.4307 - val_loss: 539.0833 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 350/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 538.6453 - mae: 0.4342\n",
      "Epoch 350: val_loss improved from 539.08331 to 538.87305, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 179ms/step - loss: 538.6353 - mae: 0.4307 - val_loss: 538.8730 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 351/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 538.4349 - mae: 0.4342\n",
      "Epoch 351: val_loss improved from 538.87305 to 538.66290, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 538.4249 - mae: 0.4307 - val_loss: 538.6629 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 352/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 538.2249 - mae: 0.4342\n",
      "Epoch 352: val_loss improved from 538.66290 to 538.45300, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 193ms/step - loss: 538.2149 - mae: 0.4307 - val_loss: 538.4530 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 353/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 538.0149 - mae: 0.4342\n",
      "Epoch 353: val_loss improved from 538.45300 to 538.24316, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 538.0049 - mae: 0.4307 - val_loss: 538.2432 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 354/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 537.8052 - mae: 0.4342\n",
      "Epoch 354: val_loss improved from 538.24316 to 538.03357, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 178ms/step - loss: 537.7952 - mae: 0.4308 - val_loss: 538.0336 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 355/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 537.5956 - mae: 0.4342\n",
      "Epoch 355: val_loss improved from 538.03357 to 537.82410, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 537.5856 - mae: 0.4308 - val_loss: 537.8241 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 356/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 537.3861 - mae: 0.4343\n",
      "Epoch 356: val_loss improved from 537.82410 to 537.61481, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 179ms/step - loss: 537.3762 - mae: 0.4308 - val_loss: 537.6148 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 357/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 537.1768 - mae: 0.4343\n",
      "Epoch 357: val_loss improved from 537.61481 to 537.40564, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 537.1668 - mae: 0.4308 - val_loss: 537.4056 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 358/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 536.9677 - mae: 0.4343\n",
      "Epoch 358: val_loss improved from 537.40564 to 537.19666, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 536.9577 - mae: 0.4308 - val_loss: 537.1967 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 359/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 536.7587 - mae: 0.4343\n",
      "Epoch 359: val_loss improved from 537.19666 to 536.98779, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 536.7487 - mae: 0.4308 - val_loss: 536.9878 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 360/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 536.5498 - mae: 0.4343\n",
      "Epoch 360: val_loss improved from 536.98779 to 536.77911, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 179ms/step - loss: 536.5399 - mae: 0.4308 - val_loss: 536.7791 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 361/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 536.3412 - mae: 0.4343\n",
      "Epoch 361: val_loss improved from 536.77911 to 536.57056, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 536.3312 - mae: 0.4308 - val_loss: 536.5706 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 362/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 536.1327 - mae: 0.4343\n",
      "Epoch 362: val_loss improved from 536.57056 to 536.36224, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 536.1227 - mae: 0.4309 - val_loss: 536.3622 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 363/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 535.9243 - mae: 0.4343\n",
      "Epoch 363: val_loss improved from 536.36224 to 536.15399, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 535.9144 - mae: 0.4309 - val_loss: 536.1540 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 364/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 535.7161 - mae: 0.4344\n",
      "Epoch 364: val_loss improved from 536.15399 to 535.94598, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 535.7062 - mae: 0.4309 - val_loss: 535.9460 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 365/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 535.5081 - mae: 0.4344\n",
      "Epoch 365: val_loss improved from 535.94598 to 535.73810, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 535.4981 - mae: 0.4309 - val_loss: 535.7381 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 366/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 535.3002 - mae: 0.4344\n",
      "Epoch 366: val_loss improved from 535.73810 to 535.53027, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 535.2902 - mae: 0.4309 - val_loss: 535.5303 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 367/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 535.0924 - mae: 0.4344\n",
      "Epoch 367: val_loss improved from 535.53027 to 535.32269, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 535.0825 - mae: 0.4309 - val_loss: 535.3227 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 368/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 534.8848 - mae: 0.4344\n",
      "Epoch 368: val_loss improved from 535.32269 to 535.11523, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 534.8749 - mae: 0.4309 - val_loss: 535.1152 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 369/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 534.6774 - mae: 0.4344\n",
      "Epoch 369: val_loss improved from 535.11523 to 534.90796, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 178ms/step - loss: 534.6674 - mae: 0.4310 - val_loss: 534.9080 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 370/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 534.4701 - mae: 0.4344\n",
      "Epoch 370: val_loss improved from 534.90796 to 534.70081, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 534.4602 - mae: 0.4310 - val_loss: 534.7008 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 371/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 534.2630 - mae: 0.4345\n",
      "Epoch 371: val_loss improved from 534.70081 to 534.49384, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 534.2531 - mae: 0.4310 - val_loss: 534.4938 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 372/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 534.0560 - mae: 0.4345\n",
      "Epoch 372: val_loss improved from 534.49384 to 534.28699, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 534.0461 - mae: 0.4310 - val_loss: 534.2870 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 373/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 533.8492 - mae: 0.4345\n",
      "Epoch 373: val_loss improved from 534.28699 to 534.08032, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 294ms/step - loss: 533.8392 - mae: 0.4310 - val_loss: 534.0803 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 374/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 533.6425 - mae: 0.4345\n",
      "Epoch 374: val_loss improved from 534.08032 to 533.87378, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 533.6326 - mae: 0.4310 - val_loss: 533.8738 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 375/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 533.4359 - mae: 0.4345\n",
      "Epoch 375: val_loss improved from 533.87378 to 533.66736, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 533.4260 - mae: 0.4310 - val_loss: 533.6674 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 376/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 533.2296 - mae: 0.4345\n",
      "Epoch 376: val_loss improved from 533.66736 to 533.46112, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 533.2197 - mae: 0.4310 - val_loss: 533.4611 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 377/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 533.0233 - mae: 0.4345\n",
      "Epoch 377: val_loss improved from 533.46112 to 533.25500, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 533.0134 - mae: 0.4311 - val_loss: 533.2550 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 378/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 532.8173 - mae: 0.4345\n",
      "Epoch 378: val_loss improved from 533.25500 to 533.04907, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 532.8074 - mae: 0.4311 - val_loss: 533.0491 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 379/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 532.6113 - mae: 0.4346\n",
      "Epoch 379: val_loss improved from 533.04907 to 532.84326, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 532.6014 - mae: 0.4311 - val_loss: 532.8433 - val_mae: 0.7219 - learning_rate: 0.0100\n",
      "Epoch 380/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 532.4055 - mae: 0.4346\n",
      "Epoch 380: val_loss improved from 532.84326 to 532.63757, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 532.3956 - mae: 0.4311 - val_loss: 532.6376 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 381/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 532.1998 - mae: 0.4346\n",
      "Epoch 381: val_loss improved from 532.63757 to 532.43207, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 532.1900 - mae: 0.4311 - val_loss: 532.4321 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 382/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 531.9944 - mae: 0.4346\n",
      "Epoch 382: val_loss improved from 532.43207 to 532.22668, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 189ms/step - loss: 531.9845 - mae: 0.4311 - val_loss: 532.2267 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 383/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 531.7890 - mae: 0.4346\n",
      "Epoch 383: val_loss improved from 532.22668 to 532.02148, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 186ms/step - loss: 531.7791 - mae: 0.4311 - val_loss: 532.0215 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 384/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 531.5839 - mae: 0.4346\n",
      "Epoch 384: val_loss improved from 532.02148 to 531.81641, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 531.5740 - mae: 0.4312 - val_loss: 531.8164 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 385/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 531.3787 - mae: 0.4346\n",
      "Epoch 385: val_loss improved from 531.81641 to 531.61145, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 531.3689 - mae: 0.4312 - val_loss: 531.6115 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 386/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 531.1738 - mae: 0.4347\n",
      "Epoch 386: val_loss improved from 531.61145 to 531.40668, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 531.1640 - mae: 0.4312 - val_loss: 531.4067 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 387/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 530.9691 - mae: 0.4347\n",
      "Epoch 387: val_loss improved from 531.40668 to 531.20203, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 530.9592 - mae: 0.4312 - val_loss: 531.2020 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 388/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 530.7644 - mae: 0.4347\n",
      "Epoch 388: val_loss improved from 531.20203 to 530.99756, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 530.7545 - mae: 0.4312 - val_loss: 530.9976 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 389/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 530.5599 - mae: 0.4347\n",
      "Epoch 389: val_loss improved from 530.99756 to 530.79315, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 530.5501 - mae: 0.4312 - val_loss: 530.7932 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 390/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 530.3555 - mae: 0.4347\n",
      "Epoch 390: val_loss improved from 530.79315 to 530.58893, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 180ms/step - loss: 530.3456 - mae: 0.4312 - val_loss: 530.5889 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 391/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 530.1513 - mae: 0.4347\n",
      "Epoch 391: val_loss improved from 530.58893 to 530.38489, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 530.1415 - mae: 0.4312 - val_loss: 530.3849 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 392/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 529.9473 - mae: 0.4347\n",
      "Epoch 392: val_loss improved from 530.38489 to 530.18091, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 529.9375 - mae: 0.4312 - val_loss: 530.1809 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 393/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 529.7433 - mae: 0.4347\n",
      "Epoch 393: val_loss improved from 530.18091 to 529.97717, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 529.7335 - mae: 0.4313 - val_loss: 529.9772 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 394/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 529.5396 - mae: 0.4348\n",
      "Epoch 394: val_loss improved from 529.97717 to 529.77350, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 529.5297 - mae: 0.4313 - val_loss: 529.7735 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 395/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 529.3359 - mae: 0.4348\n",
      "Epoch 395: val_loss improved from 529.77350 to 529.56995, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 529.3261 - mae: 0.4313 - val_loss: 529.5699 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 396/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 529.1324 - mae: 0.4348\n",
      "Epoch 396: val_loss improved from 529.56995 to 529.36664, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 529.1226 - mae: 0.4313 - val_loss: 529.3666 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 397/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 528.9291 - mae: 0.4348\n",
      "Epoch 397: val_loss improved from 529.36664 to 529.16339, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 528.9193 - mae: 0.4313 - val_loss: 529.1634 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 398/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 528.7258 - mae: 0.4348\n",
      "Epoch 398: val_loss improved from 529.16339 to 528.96027, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 528.7160 - mae: 0.4313 - val_loss: 528.9603 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 399/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 528.5228 - mae: 0.4348\n",
      "Epoch 399: val_loss improved from 528.96027 to 528.75732, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 528.5129 - mae: 0.4313 - val_loss: 528.7573 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 400/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 528.3198 - mae: 0.4348\n",
      "Epoch 400: val_loss improved from 528.75732 to 528.55450, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 528.3100 - mae: 0.4313 - val_loss: 528.5545 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 401/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 528.1170 - mae: 0.4348\n",
      "Epoch 401: val_loss improved from 528.55450 to 528.35181, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 528.1072 - mae: 0.4314 - val_loss: 528.3518 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 402/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 527.9143 - mae: 0.4349\n",
      "Epoch 402: val_loss improved from 528.35181 to 528.14923, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 206ms/step - loss: 527.9045 - mae: 0.4314 - val_loss: 528.1492 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 403/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 527.7118 - mae: 0.4349\n",
      "Epoch 403: val_loss improved from 528.14923 to 527.94684, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 206ms/step - loss: 527.7020 - mae: 0.4314 - val_loss: 527.9468 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 404/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 527.5094 - mae: 0.4349\n",
      "Epoch 404: val_loss improved from 527.94684 to 527.74457, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 195ms/step - loss: 527.4996 - mae: 0.4314 - val_loss: 527.7446 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 405/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 527.3071 - mae: 0.4349\n",
      "Epoch 405: val_loss improved from 527.74457 to 527.54242, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 201ms/step - loss: 527.2973 - mae: 0.4314 - val_loss: 527.5424 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 406/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 527.1050 - mae: 0.4349\n",
      "Epoch 406: val_loss improved from 527.54242 to 527.34039, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 527.0952 - mae: 0.4314 - val_loss: 527.3404 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 407/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 526.9030 - mae: 0.4349\n",
      "Epoch 407: val_loss improved from 527.34039 to 527.13855, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 526.8932 - mae: 0.4314 - val_loss: 527.1385 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 408/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 526.7011 - mae: 0.4349\n",
      "Epoch 408: val_loss improved from 527.13855 to 526.93677, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 526.6913 - mae: 0.4314 - val_loss: 526.9368 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 409/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 526.4994 - mae: 0.4349\n",
      "Epoch 409: val_loss improved from 526.93677 to 526.73523, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 526.4896 - mae: 0.4315 - val_loss: 526.7352 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 410/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 526.2979 - mae: 0.4350\n",
      "Epoch 410: val_loss improved from 526.73523 to 526.53375, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 526.2881 - mae: 0.4315 - val_loss: 526.5338 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 411/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 526.0964 - mae: 0.4350\n",
      "Epoch 411: val_loss improved from 526.53375 to 526.33240, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 526.0866 - mae: 0.4315 - val_loss: 526.3324 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 412/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 525.8950 - mae: 0.4350\n",
      "Epoch 412: val_loss improved from 526.33240 to 526.13123, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 525.8852 - mae: 0.4315 - val_loss: 526.1312 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 413/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 525.6938 - mae: 0.4350\n",
      "Epoch 413: val_loss improved from 526.13123 to 525.93011, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 525.6841 - mae: 0.4315 - val_loss: 525.9301 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 414/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 167ms/step - loss: 525.4928 - mae: 0.4350\n",
      "Epoch 414: val_loss improved from 525.93011 to 525.72919, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 525.4830 - mae: 0.4315 - val_loss: 525.7292 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 415/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 165ms/step - loss: 525.2919 - mae: 0.4350\n",
      "Epoch 415: val_loss improved from 525.72919 to 525.52838, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 185ms/step - loss: 525.2821 - mae: 0.4315 - val_loss: 525.5284 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 416/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 171ms/step - loss: 525.0911 - mae: 0.4350\n",
      "Epoch 416: val_loss improved from 525.52838 to 525.32770, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 525.0814 - mae: 0.4315 - val_loss: 525.3277 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 417/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 166ms/step - loss: 524.8904 - mae: 0.4350\n",
      "Epoch 417: val_loss improved from 525.32770 to 525.12720, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 187ms/step - loss: 524.8806 - mae: 0.4316 - val_loss: 525.1272 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 418/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 524.6899 - mae: 0.4351\n",
      "Epoch 418: val_loss improved from 525.12720 to 524.92676, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 183ms/step - loss: 524.6801 - mae: 0.4316 - val_loss: 524.9268 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 419/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 170ms/step - loss: 524.4895 - mae: 0.4351\n",
      "Epoch 419: val_loss improved from 524.92676 to 524.72644, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 524.4797 - mae: 0.4316 - val_loss: 524.7264 - val_mae: 0.7218 - learning_rate: 0.0100\n",
      "Epoch 420/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 524.2892 - mae: 0.4351\n",
      "Epoch 420: val_loss improved from 524.72644 to 524.52637, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 182ms/step - loss: 524.2795 - mae: 0.4316 - val_loss: 524.5264 - val_mae: 0.7217 - learning_rate: 0.0100\n",
      "Epoch 421/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 169ms/step - loss: 524.0891 - mae: 0.4351\n",
      "Epoch 421: val_loss improved from 524.52637 to 524.32635, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 524.0794 - mae: 0.4316 - val_loss: 524.3264 - val_mae: 0.7217 - learning_rate: 0.0100\n",
      "Epoch 422/1000\n",
      "\u001B[1m1/2\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 168ms/step - loss: 523.8891 - mae: 0.4351\n",
      "Epoch 422: val_loss improved from 524.32635 to 524.12646, saving model to best_model_merged.keras\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 181ms/step - loss: 523.8794 - mae: 0.4316 - val_loss: 524.1265 - val_mae: 0.7217 - learning_rate: 0.0100\n",
      "Epoch 423/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m train_and_merge_models(data_folder, output_columns, feature_shape, label_shape, cache_base_dir)\n",
      "Cell \u001B[1;32mIn[5], line 85\u001B[0m, in \u001B[0;36mtrain_and_merge_models\u001B[1;34m(data_folder, output_columns, feature_shape, label_shape, cache_base_dir, split_ratio, batch_size)\u001B[0m\n\u001B[0;32m     81\u001B[0m model_checkpoint \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mModelCheckpoint(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbest_model_merged.keras\u001B[39m\u001B[38;5;124m\"\u001B[39m, monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m     82\u001B[0m                                                    save_best_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     84\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m---> 85\u001B[0m history \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfit(dataset_train, validation_data\u001B[38;5;241m=\u001B[39mdataset_val, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m,\n\u001B[0;32m     86\u001B[0m                     callbacks\u001B[38;5;241m=\u001B[39m[\n\u001B[0;32m     87\u001B[0m                         lr_reducer, early_stop, model_checkpoint\u001B[38;5;66;03m#, WandbMetricsLogger()\u001B[39;00m\n\u001B[0;32m     88\u001B[0m                     ])\n\u001B[0;32m     90\u001B[0m \u001B[38;5;66;03m# Extract and log-transform the loss data\u001B[39;00m\n\u001B[0;32m     91\u001B[0m epoch \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m]) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\backend\\torch\\trainer.py:256\u001B[0m, in \u001B[0;36mTorchTrainer.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, data \u001B[38;5;129;01min\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39menumerate_epoch():\n\u001B[0;32m    253\u001B[0m     \u001B[38;5;66;03m# Callbacks\u001B[39;00m\n\u001B[0;32m    254\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m--> 256\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_function(data)\n\u001B[0;32m    257\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pythonify_logs(logs)\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;66;03m# Callbacks\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\backend\\torch\\trainer.py:117\u001B[0m, in \u001B[0;36mTorchTrainer.make_train_function.<locals>.one_step_on_data\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001B[39;00m\n\u001B[0;32m    116\u001B[0m data \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m--> 117\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_step(data)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\backend\\torch\\trainer.py:44\u001B[0m, in \u001B[0;36mTorchTrainer.train_step\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# Compute predictions\u001B[39;00m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_has_training_arg:\n\u001B[1;32m---> 44\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m(x, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     46\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m(x)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\layers\\layer.py:901\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    899\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 901\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    902\u001B[0m \u001B[38;5;66;03m# Change the layout for the layer output if needed.\u001B[39;00m\n\u001B[0;32m    903\u001B[0m \u001B[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001B[39;00m\n\u001B[0;32m    904\u001B[0m \u001B[38;5;66;03m# to achieve the optimal performance.\u001B[39;00m\n\u001B[0;32m    905\u001B[0m distribution \u001B[38;5;241m=\u001B[39m distribution_lib\u001B[38;5;241m.\u001B[39mdistribution()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py:38\u001B[0m, in \u001B[0;36mTorchLayer.forward\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Operation\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\ops\\operation.py:46\u001B[0m, in \u001B[0;36mOperation.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     41\u001B[0m             call_fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcall\n\u001B[0;32m     42\u001B[0m     call_fn \u001B[38;5;241m=\u001B[39m traceback_utils\u001B[38;5;241m.\u001B[39minject_argument_info_in_traceback(\n\u001B[0;32m     43\u001B[0m         call_fn,\n\u001B[0;32m     44\u001B[0m         object_name\u001B[38;5;241m=\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.call()\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m     45\u001B[0m     )\n\u001B[1;32m---> 46\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m call_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# Plain flow.\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    154\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    159\u001B[0m         \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\models\\functional.py:175\u001B[0m, in \u001B[0;36mFunctional.call\u001B[1;34m(self, inputs, training, mask)\u001B[0m\n\u001B[0;32m    173\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    174\u001B[0m             x\u001B[38;5;241m.\u001B[39m_keras_mask \u001B[38;5;241m=\u001B[39m mask\n\u001B[1;32m--> 175\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_through_graph(\n\u001B[0;32m    176\u001B[0m     inputs, operation_fn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m op: operation_fn(op, training\u001B[38;5;241m=\u001B[39mtraining)\n\u001B[0;32m    177\u001B[0m )\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m unpack_singleton(outputs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\ops\\function.py:171\u001B[0m, in \u001B[0;36mFunction._run_through_graph\u001B[1;34m(self, inputs, operation_fn, call_fn)\u001B[0m\n\u001B[0;32m    169\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m call_fn(op, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    170\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 171\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m op(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    173\u001B[0m \u001B[38;5;66;03m# Update tensor_dict.\u001B[39;00m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x, y \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(node\u001B[38;5;241m.\u001B[39moutputs, tree\u001B[38;5;241m.\u001B[39mflatten(outputs)):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\models\\functional.py:560\u001B[0m, in \u001B[0;36moperation_fn.<locals>.call\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    554\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    555\u001B[0m     \u001B[38;5;28mhasattr\u001B[39m(operation, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_call_has_training_arg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    556\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m operation\u001B[38;5;241m.\u001B[39m_call_has_training_arg\n\u001B[0;32m    557\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m training \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    558\u001B[0m ):\n\u001B[0;32m    559\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m training\n\u001B[1;32m--> 560\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m operation(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\layers\\layer.py:901\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    899\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 901\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    902\u001B[0m \u001B[38;5;66;03m# Change the layout for the layer output if needed.\u001B[39;00m\n\u001B[0;32m    903\u001B[0m \u001B[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001B[39;00m\n\u001B[0;32m    904\u001B[0m \u001B[38;5;66;03m# to achieve the optimal performance.\u001B[39;00m\n\u001B[0;32m    905\u001B[0m distribution \u001B[38;5;241m=\u001B[39m distribution_lib\u001B[38;5;241m.\u001B[39mdistribution()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py:38\u001B[0m, in \u001B[0;36mTorchLayer.forward\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Operation\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\ops\\operation.py:46\u001B[0m, in \u001B[0;36mOperation.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     41\u001B[0m             call_fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcall\n\u001B[0;32m     42\u001B[0m     call_fn \u001B[38;5;241m=\u001B[39m traceback_utils\u001B[38;5;241m.\u001B[39minject_argument_info_in_traceback(\n\u001B[0;32m     43\u001B[0m         call_fn,\n\u001B[0;32m     44\u001B[0m         object_name\u001B[38;5;241m=\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.call()\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m     45\u001B[0m     )\n\u001B[1;32m---> 46\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m call_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# Plain flow.\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    154\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    159\u001B[0m         \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:221\u001B[0m, in \u001B[0;36mBidirectional.call\u001B[1;34m(self, sequences, initial_state, mask, training)\u001B[0m\n\u001B[0;32m    216\u001B[0m     forward_state, backward_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    218\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_layer(\n\u001B[0;32m    219\u001B[0m     forward_inputs, initial_state\u001B[38;5;241m=\u001B[39mforward_state, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    220\u001B[0m )\n\u001B[1;32m--> 221\u001B[0m y_rev \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackward_layer(\n\u001B[0;32m    222\u001B[0m     backward_inputs, initial_state\u001B[38;5;241m=\u001B[39mbackward_state, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    223\u001B[0m )\n\u001B[0;32m    225\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_state:\n\u001B[0;32m    226\u001B[0m     states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(y[\u001B[38;5;241m1\u001B[39m:] \u001B[38;5;241m+\u001B[39m y_rev[\u001B[38;5;241m1\u001B[39m:])\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\layers\\layer.py:901\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    899\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 901\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    902\u001B[0m \u001B[38;5;66;03m# Change the layout for the layer output if needed.\u001B[39;00m\n\u001B[0;32m    903\u001B[0m \u001B[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001B[39;00m\n\u001B[0;32m    904\u001B[0m \u001B[38;5;66;03m# to achieve the optimal performance.\u001B[39;00m\n\u001B[0;32m    905\u001B[0m distribution \u001B[38;5;241m=\u001B[39m distribution_lib\u001B[38;5;241m.\u001B[39mdistribution()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py:38\u001B[0m, in \u001B[0;36mTorchLayer.forward\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Operation\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\ops\\operation.py:46\u001B[0m, in \u001B[0;36mOperation.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     41\u001B[0m             call_fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcall\n\u001B[0;32m     42\u001B[0m     call_fn \u001B[38;5;241m=\u001B[39m traceback_utils\u001B[38;5;241m.\u001B[39minject_argument_info_in_traceback(\n\u001B[0;32m     43\u001B[0m         call_fn,\n\u001B[0;32m     44\u001B[0m         object_name\u001B[38;5;241m=\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.call()\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m     45\u001B[0m     )\n\u001B[1;32m---> 46\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m call_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# Plain flow.\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    154\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    159\u001B[0m         \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:570\u001B[0m, in \u001B[0;36mLSTM.call\u001B[1;34m(self, sequences, initial_state, mask, training)\u001B[0m\n\u001B[0;32m    569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, sequences, initial_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m--> 570\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mcall(\n\u001B[0;32m    571\u001B[0m         sequences, mask\u001B[38;5;241m=\u001B[39mmask, training\u001B[38;5;241m=\u001B[39mtraining, initial_state\u001B[38;5;241m=\u001B[39minitial_state\n\u001B[0;32m    572\u001B[0m     )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:406\u001B[0m, in \u001B[0;36mRNN.call\u001B[1;34m(self, sequences, initial_state, mask, training)\u001B[0m\n\u001B[0;32m    400\u001B[0m \u001B[38;5;66;03m# Prepopulate the dropout state so that the inner_loop is stateless\u001B[39;00m\n\u001B[0;32m    401\u001B[0m \u001B[38;5;66;03m# this is particularly important for JAX backend.\u001B[39;00m\n\u001B[0;32m    402\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_config_dropout_masks(\n\u001B[0;32m    403\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcell, sequences[:, \u001B[38;5;241m0\u001B[39m, :], initial_state\n\u001B[0;32m    404\u001B[0m )\n\u001B[1;32m--> 406\u001B[0m last_output, outputs, states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minner_loop(\n\u001B[0;32m    407\u001B[0m     sequences\u001B[38;5;241m=\u001B[39msequences,\n\u001B[0;32m    408\u001B[0m     initial_state\u001B[38;5;241m=\u001B[39minitial_state,\n\u001B[0;32m    409\u001B[0m     mask\u001B[38;5;241m=\u001B[39mmask,\n\u001B[0;32m    410\u001B[0m     training\u001B[38;5;241m=\u001B[39mtraining,\n\u001B[0;32m    411\u001B[0m )\n\u001B[0;32m    412\u001B[0m last_output \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mcast(last_output, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_dtype)\n\u001B[0;32m    413\u001B[0m outputs \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mcast(outputs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_dtype)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:565\u001B[0m, in \u001B[0;36mLSTM.inner_loop\u001B[1;34m(self, sequences, initial_state, mask, training)\u001B[0m\n\u001B[0;32m    558\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_cudnn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    559\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    560\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse_cudnn=True was specified, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    561\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut cuDNN is not supported for this layer configuration \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    562\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwith this backend. Pass use_cudnn=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m to fallback \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    563\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto a non-cuDNN implementation.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    564\u001B[0m     )\n\u001B[1;32m--> 565\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39minner_loop(\n\u001B[0;32m    566\u001B[0m     sequences, initial_state, mask\u001B[38;5;241m=\u001B[39mmask, training\u001B[38;5;241m=\u001B[39mtraining\n\u001B[0;32m    567\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:346\u001B[0m, in \u001B[0;36mRNN.inner_loop\u001B[1;34m(self, sequences, initial_state, mask, training)\u001B[0m\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tree\u001B[38;5;241m.\u001B[39mis_nested(initial_state):\n\u001B[0;32m    344\u001B[0m     initial_state \u001B[38;5;241m=\u001B[39m [initial_state]\n\u001B[1;32m--> 346\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m backend\u001B[38;5;241m.\u001B[39mrnn(\n\u001B[0;32m    347\u001B[0m     step,\n\u001B[0;32m    348\u001B[0m     sequences,\n\u001B[0;32m    349\u001B[0m     initial_state,\n\u001B[0;32m    350\u001B[0m     go_backwards\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgo_backwards,\n\u001B[0;32m    351\u001B[0m     mask\u001B[38;5;241m=\u001B[39mmask,\n\u001B[0;32m    352\u001B[0m     unroll\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munroll,\n\u001B[0;32m    353\u001B[0m     input_length\u001B[38;5;241m=\u001B[39msequences\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m],\n\u001B[0;32m    354\u001B[0m     zero_output_for_mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mzero_output_for_mask,\n\u001B[0;32m    355\u001B[0m     return_all_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_sequences,\n\u001B[0;32m    356\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\backend\\torch\\rnn.py:347\u001B[0m, in \u001B[0;36mrnn\u001B[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001B[0m\n\u001B[0;32m    345\u001B[0m new_states \u001B[38;5;241m=\u001B[39m states\n\u001B[0;32m    346\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m time \u001B[38;5;241m<\u001B[39m time_steps_t \u001B[38;5;129;01mand\u001B[39;00m it \u001B[38;5;241m<\u001B[39m max_iterations:\n\u001B[1;32m--> 347\u001B[0m     final_outputs \u001B[38;5;241m=\u001B[39m _step(time, output_ta_t, \u001B[38;5;241m*\u001B[39mnew_states)\n\u001B[0;32m    348\u001B[0m     time, output_ta_t \u001B[38;5;241m=\u001B[39m final_outputs[:\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m    349\u001B[0m     new_states \u001B[38;5;241m=\u001B[39m final_outputs[\u001B[38;5;241m2\u001B[39m:]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\backend\\torch\\rnn.py:328\u001B[0m, in \u001B[0;36mrnn.<locals>._step\u001B[1;34m(time, output_ta_t, *states)\u001B[0m\n\u001B[0;32m    326\u001B[0m current_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(ta[time] \u001B[38;5;28;01mfor\u001B[39;00m ta \u001B[38;5;129;01min\u001B[39;00m input_ta)\n\u001B[0;32m    327\u001B[0m current_input \u001B[38;5;241m=\u001B[39m tree\u001B[38;5;241m.\u001B[39mpack_sequence_as(inputs, current_input)\n\u001B[1;32m--> 328\u001B[0m output, new_states \u001B[38;5;241m=\u001B[39m step_function(\n\u001B[0;32m    329\u001B[0m     current_input, \u001B[38;5;28mtuple\u001B[39m(states) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mtuple\u001B[39m(constants)\n\u001B[0;32m    330\u001B[0m )\n\u001B[0;32m    331\u001B[0m flat_new_state \u001B[38;5;241m=\u001B[39m tree\u001B[38;5;241m.\u001B[39mflatten(new_states)\n\u001B[0;32m    333\u001B[0m flat_output \u001B[38;5;241m=\u001B[39m tree\u001B[38;5;241m.\u001B[39mflatten(output)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:338\u001B[0m, in \u001B[0;36mRNN.inner_loop.<locals>.step\u001B[1;34m(inputs, states)\u001B[0m\n\u001B[0;32m    337\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(inputs, states):\n\u001B[1;32m--> 338\u001B[0m     output, new_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcell(inputs, states, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcell_kwargs)\n\u001B[0;32m    339\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tree\u001B[38;5;241m.\u001B[39mis_nested(new_states):\n\u001B[0;32m    340\u001B[0m         new_states \u001B[38;5;241m=\u001B[39m [new_states]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\layers\\layer.py:901\u001B[0m, in \u001B[0;36mLayer.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    899\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 901\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    902\u001B[0m \u001B[38;5;66;03m# Change the layout for the layer output if needed.\u001B[39;00m\n\u001B[0;32m    903\u001B[0m \u001B[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001B[39;00m\n\u001B[0;32m    904\u001B[0m \u001B[38;5;66;03m# to achieve the optimal performance.\u001B[39;00m\n\u001B[0;32m    905\u001B[0m distribution \u001B[38;5;241m=\u001B[39m distribution_lib\u001B[38;5;241m.\u001B[39mdistribution()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py:38\u001B[0m, in \u001B[0;36mTorchLayer.forward\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Operation\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\ops\\operation.py:46\u001B[0m, in \u001B[0;36mOperation.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     41\u001B[0m             call_fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcall\n\u001B[0;32m     42\u001B[0m     call_fn \u001B[38;5;241m=\u001B[39m traceback_utils\u001B[38;5;241m.\u001B[39minject_argument_info_in_traceback(\n\u001B[0;32m     43\u001B[0m         call_fn,\n\u001B[0;32m     44\u001B[0m         object_name\u001B[38;5;241m=\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.call()\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m     45\u001B[0m     )\n\u001B[1;32m---> 46\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m call_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# Plain flow.\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001B[0m, in \u001B[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    154\u001B[0m bound_signature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_keras_call_info_injected\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    159\u001B[0m         \u001B[38;5;66;03m# Only inject info for the innermost failing call\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:264\u001B[0m, in \u001B[0;36mLSTMCell.call\u001B[1;34m(self, inputs, states, training)\u001B[0m\n\u001B[0;32m    262\u001B[0m     c, o \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_carry_and_output(x, h_tm1, c_tm1)\n\u001B[0;32m    263\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 264\u001B[0m     z \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mmatmul(inputs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel)\n\u001B[0;32m    266\u001B[0m     z \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mmatmul(h_tm1, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecurrent_kernel)\n\u001B[0;32m    267\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_bias:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\ops\\numpy.py:3445\u001B[0m, in \u001B[0;36mmatmul\u001B[1;34m(x1, x2)\u001B[0m\n\u001B[0;32m   3443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m any_symbolic_tensors((x1, x2)):\n\u001B[0;32m   3444\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Matmul()\u001B[38;5;241m.\u001B[39msymbolic_call(x1, x2)\n\u001B[1;32m-> 3445\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m backend\u001B[38;5;241m.\u001B[39mnumpy\u001B[38;5;241m.\u001B[39mmatmul(x1, x2)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Nao\\Lib\\site-packages\\keras\\src\\backend\\torch\\numpy.py:114\u001B[0m, in \u001B[0;36mmatmul\u001B[1;34m(x1, x2)\u001B[0m\n\u001B[0;32m    112\u001B[0m x1 \u001B[38;5;241m=\u001B[39m cast(x1, compute_dtype)\n\u001B[0;32m    113\u001B[0m x2 \u001B[38;5;241m=\u001B[39m cast(x2, compute_dtype)\n\u001B[1;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cast(torch\u001B[38;5;241m.\u001B[39mmatmul(x1, x2), result_dtype)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:54:29.631841Z",
     "start_time": "2024-08-28T07:54:29.625841Z"
    }
   },
   "source": [
    "def restore_scale(predictions, label_ranges):\n",
    "    restored_predictions = []\n",
    "    for i, label in enumerate(label_ranges.keys()):\n",
    "        min_val, max_val = label_ranges[label]\n",
    "        normalized_value = predictions[0]\n",
    "\n",
    "        if min_val < 0:\n",
    "            original_value = ((normalized_value + 1) / 2) * (max_val - min_val) + min_val\n",
    "        else:\n",
    "            original_value = normalized_value * (max_val - min_val) + min_val\n",
    "\n",
    "        restored_predictions.append(original_value)\n",
    "    return np.array(restored_predictions)\n",
    "    \n",
    "def calculate_prediction(dataset, model, label_ranges):\n",
    "    all_predictions = {label: [] for label in label_ranges.keys()}\n",
    "    all_actuals = {label: [] for label in label_ranges.keys()}\n",
    "\n",
    "    for batch_data in dataset:\n",
    "        features = batch_data[0]\n",
    "        output_label = 'output_' + list(label_ranges.keys())[0]\n",
    "        labels = batch_data[1][output_label].cpu().detach().numpy()\n",
    "\n",
    "        predictions = np.array([p.cpu().detach().numpy() for p in model(features)[output_label]])\n",
    "        for i in range(len(features)):\n",
    "            restored_predictions = restore_scale(predictions[i], label_ranges)\n",
    "            actual_labels = [labels[i]]\n",
    "            restored_actual_labels = restore_scale(actual_labels, label_ranges)\n",
    "\n",
    "            for j, label in enumerate(label_ranges.keys()):\n",
    "                all_predictions[label].append(restored_predictions[j])\n",
    "                all_actuals[label].append(restored_actual_labels[j])\n",
    "    \n",
    "    return all_predictions, all_actuals\n",
    "\n",
    "def plot_predictions(predications, actuals):\n",
    "    for label in predications.keys():\n",
    "        plt.figure()\n",
    "        \n",
    "        plt.plot(predications[label], label='Prediction')\n",
    "        \n",
    "        plt.plot(actuals[label], label='Actual', linestyle='--')\n",
    "        \n",
    "        # Set plot details\n",
    "        plt.title(f'Prediction vs Actual for {label}')\n",
    "        plt.xlabel('Data Point Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:54:30.855367Z",
     "start_time": "2024-08-28T07:54:29.964161Z"
    }
   },
   "source": [
    "dataset = create_dataset(data_folder, output_columns, label_shape, cache_path=cache_base_dir)\n",
    "dataset_train, dataset_val = split_dataset(dataset, 0.8, 1024)\n",
    "for output_column in output_columns:\n",
    "    model = keras.models.load_model(f\"best_model_merged.keras\")\n",
    "    label_ranges = {column: column_ranges[column] for column in [output_column] if column in column_ranges}\n",
    "    predications, actuals = calculate_prediction(dataset_train, model, label_ranges)\n",
    "    plot_predictions(predications, actuals)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
